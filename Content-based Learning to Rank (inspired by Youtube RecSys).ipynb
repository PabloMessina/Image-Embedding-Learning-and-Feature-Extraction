{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from os import path\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a single GPU because we want to be nice with other people :)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load pre-trained ResNet50 image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_and_ids(dirpath, embedding_file, ids_file):\n",
    "    embeddings = np.load(path.join(dirpath, embedding_file))\n",
    "    with open(path.join(dirpath, ids_file)) as f:\n",
    "        ids = [int(x) for x in f.readlines()]\n",
    "        id2index = { _id:i for i,_id in enumerate(ids) }    \n",
    "    assert (embeddings.shape[0] == len(ids))\n",
    "    return embeddings, ids, id2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_embeddings,\\\n",
    "artwork_ids,\\\n",
    "artwork_id2index = load_embeddings_and_ids(\n",
    "'/mnt/workspace/Ugallery/ResNet50/', 'flatten_1.npy', 'ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13297"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_artworks = len(artwork_ids)\n",
    "n_artworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('./valid_sales.csv')\n",
    "artworks_df = pd.read_csv('./valid_artworks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_ids = np.full((n_artworks,), -1, dtype=int)\n",
    "for _artworkId, _artistId in zip(artworks_df.id, artworks_df.artist_id):\n",
    "    i = artwork_id2index[_artworkId]\n",
    "    artist_ids[i] = _artistId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistId2artworkIndexes = dict()\n",
    "for i, _artistId in enumerate(artist_ids):\n",
    "    if _artistId == -1:\n",
    "        continue\n",
    "    try:\n",
    "        artistId2artworkIndexes[_artistId].append(i)\n",
    "    except KeyError:\n",
    "        artistId2artworkIndexes[_artistId] = [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect transactions per user (making sure we hide the last nonfirst purchase basket per user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, uid):\n",
    "        self._uid = uid\n",
    "        self.artwork_ids = []\n",
    "        self.artwork_idxs = []\n",
    "        self.artwork_idxs_set = set()\n",
    "        self.timestamps = []\n",
    "        self.artist_ids_set = set()\n",
    "        \n",
    "    def clear(self):\n",
    "        self.artwork_ids.clear()\n",
    "        self.artwork_idxs.clear()\n",
    "        self.artwork_idxs_set.clear()        \n",
    "        self.artist_ids_set.clear()\n",
    "        self.timestamps.clear()\n",
    "        \n",
    "    def append_transaction(self, artwork_id, timestamp):\n",
    "        aidx = artwork_id2index[artwork_id]\n",
    "        self.artwork_ids.append(artwork_id)\n",
    "        self.artwork_idxs.append(aidx)\n",
    "        self.artwork_idxs_set.add(aidx)\n",
    "        self.artist_ids_set.add(artist_ids[aidx])\n",
    "        self.timestamps.append(timestamp)\n",
    "    \n",
    "    def remove_last_nonfirst_purchase_basket(self):\n",
    "        baskets = self.baskets\n",
    "        if len(baskets) >= 2:\n",
    "            last_b = baskets.pop()            \n",
    "            artwork_ids = self.artwork_ids[:last_b[0]]\n",
    "            timestamps = self.timestamps[:last_b[0]]\n",
    "            self.clear()\n",
    "            for aid, t in zip(artwork_ids, timestamps):\n",
    "                self.append_transaction(aid, t)\n",
    "        \n",
    "    def build_purchase_baskets(self):\n",
    "        baskets = []\n",
    "        prev_t = None\n",
    "        offset = 0\n",
    "        count = 0\n",
    "        for i, t in enumerate(self.timestamps):\n",
    "            if t != prev_t:\n",
    "                if prev_t is not None:\n",
    "                    baskets.append((offset, count))\n",
    "                    offset = i\n",
    "                count = 1\n",
    "            else:\n",
    "                count += 1\n",
    "            prev_t = t\n",
    "        baskets.append((offset, count))\n",
    "        self.baskets = baskets\n",
    "        \n",
    "    def sanity_check_purchase_baskets(self):\n",
    "        ids = self.artwork_ids\n",
    "        ts = self.timestamps\n",
    "        baskets = self.baskets        \n",
    "        n = len(ts)\n",
    "        assert(len(ids) == len(ts))\n",
    "        assert(len(baskets) > 0)\n",
    "        assert (n > 0)\n",
    "        for b in baskets:\n",
    "            for j in range(b[0], b[0] + b[1] - 1):\n",
    "                assert(ts[j] == ts[j+1])\n",
    "        for i in range(1, len(baskets)):\n",
    "            b1 = baskets[i-1]\n",
    "            b2 = baskets[i]\n",
    "            assert(b1[0] + b1[1] == b2[0])\n",
    "        assert(baskets[0][0] == 0)\n",
    "        assert(baskets[-1][0] + baskets[-1][1] == n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = sales_df.customer_id.unique()\n",
    "user_id2index = { _id:i for i,_id in enumerate(user_ids) }\n",
    "users = [User(uid) for uid in user_ids]\n",
    "n_users = len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect and sanity check transactions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sales_df = sales_df.sort_values('order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear structures to prevent possible duplicate elements\n",
    "for user in users:\n",
    "    user.clear()\n",
    "\n",
    "# collect transactions per user sorted by timestamp\n",
    "for uid, aid, t in zip(sorted_sales_df.customer_id,\n",
    "                       sorted_sales_df.artwork_id,\n",
    "                       sorted_sales_df.order_date):\n",
    "    users[user_id2index[uid]].append_transaction(aid,t)\n",
    "    assert users[user_id2index[uid]]._uid == uid\n",
    "    \n",
    "# bin transctions with same timestamps into purchase baskets\n",
    "for user in users:\n",
    "    user.build_purchase_baskets()\n",
    "    user.sanity_check_purchase_baskets()\n",
    "#     user.remove_last_nonfirst_purchase_basket()\n",
    "#     user.sanity_check_purchase_baskets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute minimun cosine distance from each user profile to each item in the dataset\n",
    "\\* using R200 vectors obtained with PCA(200) over ResNet50 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_PCA200 = PCA(n_components=200).fit_transform(resnet50_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 200)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_PCA200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat = squareform(pdist(resnet50_PCA200, 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2artwork_mindist = np.empty((n_users, n_artworks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [00:45<00:00, 64.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for ui in tqdm(range(n_users)):\n",
    "    for ai in range(n_artworks):\n",
    "        user2artwork_mindist[ui][ai] = min(distmat[ai][j] for j in users[ui].artwork_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_instance(instance, pos_is_purchased=True):\n",
    "    profile = instance[0]\n",
    "    pos = instance[1]\n",
    "    neg = instance[2]    \n",
    "    assert neg != pos\n",
    "    \n",
    "    if instance[3] == -1:        \n",
    "        return # fake user\n",
    "    \n",
    "    user = users[instance[3]]\n",
    "    try:\n",
    "        assert all(i in user.artwork_idxs_set for i in profile)\n",
    "        if pos_is_purchased is not None:\n",
    "            if pos_is_purchased:\n",
    "                assert pos in user.artwork_idxs_set\n",
    "            else:\n",
    "                assert pos not in user.artwork_idxs_set\n",
    "        assert neg not in user.artwork_idxs_set\n",
    "        assert artist_ids[neg] not in user.artist_ids_set\n",
    "    except AssertionError:\n",
    "        print(t)\n",
    "        print('user._uid = ', user._uid)\n",
    "        print('user.artwork_idxs = ', user.artwork_idxs)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_instance(container, instance, **kwargs):\n",
    "    sanity_check_instance(instance, **kwargs)\n",
    "    container.append(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Given a list of purchased items, each purchased item should trivially be ranked higher than any item of non-purchased artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist(profile_artist_ids):\n",
    "    while True:\n",
    "        i = random.randint(0, n_artworks-1)\n",
    "        if artist_ids[i] not in profile_artist_ids:\n",
    "            return i\n",
    "    \n",
    "def sample_artwork_index__notsharingartist__notinprofile(profile_artist_ids, profile_artwork_idxs):\n",
    "    while True:\n",
    "        i = random.randint(0, n_artworks-1)\n",
    "        if i not in profile_artwork_idxs and artist_ids[i] not in profile_artist_ids:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_above_nonpurchased__real_users(n_test_samples=5000, n_reps=2):\n",
    "    \n",
    "    # --- train instances\n",
    "    print('sampling train instances ....')\n",
    "    for ui, user in enumerate(users):\n",
    "        u_artwork_idxs = user.artwork_idxs\n",
    "        u_artist_ids = user.artist_ids_set\n",
    "        n = len(u_artwork_idxs)        \n",
    "        \n",
    "        for k in range(1,n+1):\n",
    "            for _ in range(n_reps):\n",
    "                sample_profile = random.sample(u_artwork_idxs, k)\n",
    "                for pi in sample_profile:\n",
    "                    ni = sample_artwork_index__notsharingartist(u_artist_ids)\n",
    "                    append_instance(train_instances, (sample_profile, pi, ni, ui))\n",
    "        \n",
    "    # --- test instances\n",
    "    print('sampling test instances ....')\n",
    "    for _ in range(n_test_samples):\n",
    "        ui = random.randint(0,n_users-1)\n",
    "        user = users[ui]\n",
    "        k = random.randint(1, len(user.artwork_idxs))\n",
    "        sample_profile = random.sample(user.artwork_idxs, k)\n",
    "        pi = random.choice(sample_profile)\n",
    "        ni = sample_artwork_index__notsharingartist(user.artist_ids_set)\n",
    "        append_instance(test_instances, (sample_profile, pi, ni, ui))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_artwork_indexes = list(range(n_artworks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_above_nonpurchased__fake_users(\n",
    "        instances_container, n_samples=10000, profile_size=1):\n",
    "    for _ in range(n_samples):\n",
    "        profile = random.sample(all_artwork_indexes, profile_size)\n",
    "        profile_idxs_set = set(profile)\n",
    "        profile_artist_ids_set = set(artist_ids[i] for i in profile if artist_ids[i] != -1)\n",
    "        pi = random.choice(profile)\n",
    "        ni = sample_artwork_index__notsharingartist__notinprofile(profile_artist_ids_set, profile_idxs_set)\n",
    "        append_instance(instances_container, (profile, pi, ni, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ....\n",
      "sampling test instances ....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(187680, 10000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_samples__rank_purchased_above_nonpurchased__real_users(n_test_samples=10000, n_reps=3)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362680, 25000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in range(1,6):\n",
    "    generate_samples__rank_purchased_above_nonpurchased__fake_users(\n",
    "        train_instances, n_samples=35000, profile_size=x)\n",
    "    generate_samples__rank_purchased_above_nonpurchased__fake_users(\n",
    "        test_instances, n_samples=3000, profile_size=x)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Given a list of purchased items, any non-purchased item sharing the same artist with a purchased item should be ranked higher than any item of a non-purchased artist as long as ResNet50 doesn't disagree by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonpurchased_sharingartist(artist_id, artwork_idxs_set):\n",
    "    candidate_idxs = artistId2artworkIndexes[artist_id]\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        i = random.choice(candidate_idxs)\n",
    "        if i not in artwork_idxs_set:\n",
    "            return i\n",
    "    return None # failed to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_user_positive_negative_triplet(ui, pi, ni, threshold=0.55):\n",
    "    dp = user2artwork_mindist[ui][pi]\n",
    "    dn = user2artwork_mindist[ui][ni]\n",
    "    assert dp + dn > 0\n",
    "    return dp / (dp + dn) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, threshold):\n",
    "    while True:\n",
    "        ni = sample_artwork_index__notsharingartist(users[ui].artist_ids_set)\n",
    "        if not reject_user_positive_negative_triplet(ui, pi, ni, threshold=threshold):\n",
    "            return ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_artist_above_nonpurchased_artist(instances_container, n_samples):\n",
    "    while n_samples > 0:\n",
    "        ui = random.randint(0,n_users-1)\n",
    "        user = users[ui]\n",
    "        k = random.randint(1, len(user.artwork_idxs))\n",
    "        sample_profile = random.sample(user.artwork_idxs, k)\n",
    "        for _ in range(3):\n",
    "            aid = artist_ids[random.choice(sample_profile)]\n",
    "            assert aid != -1\n",
    "            pi = sample_artwork_index__nonpurchased_sharingartist(aid, user.artwork_idxs_set)\n",
    "            if pi is None:\n",
    "                continue\n",
    "            ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.55)\n",
    "            append_instance(instances_container, (sample_profile, pi, ni, ui), pos_is_purchased=False)\n",
    "            n_samples -= 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(512680, 35000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_purchased_artist_above_nonpurchased_artist(train_instances, n_samples=150000)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_purchased_artist_above_nonpurchased_artist(test_instances, n_samples=10000)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Given all previous purchases, rank each  item of the next purchase basket higher than any item of non-purchased artists as long as ResNet50 doesn't disagree by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_rank_next(n_neg_per_pos=10):\n",
    "    for ui, user in enumerate(users):\n",
    "        past_items = []\n",
    "        n = len(user.baskets)\n",
    "        for i in range(n-1):\n",
    "            cur_b = user.baskets[i]\n",
    "            for j in range(cur_b[0], cur_b[0] + cur_b[1]):\n",
    "                past_items.append(user.artwork_idxs[j])\n",
    "            next_b  = user.baskets[i+1]\n",
    "            profile = past_items.copy()\n",
    "            for p in range(next_b[0], next_b[0] + next_b[1]):\n",
    "                \n",
    "                pi = user.artwork_idxs[p]\n",
    "                \n",
    "                # train instances\n",
    "                for _ in range(n_neg_per_pos):\n",
    "                    ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.54)\n",
    "                    append_instance(train_instances, (profile, pi, ni, ui))\n",
    "\n",
    "                # test instance\n",
    "                ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.54)\n",
    "                append_instance(test_instances, (profile, pi, ni, ui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605920, 40328)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_samples__given_past_rank_next(n_neg_per_pos=35)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Given only the present purchase basket, hide one and rank it higher than any item of non-purchased artists as long as ResNet50 doesn't disagree by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_present_hide_rank_one(n_neg_per_pos=10):\n",
    "    for ui, user in enumerate(users):\n",
    "        for b in user.baskets:\n",
    "            if b[1] < 2:\n",
    "                continue\n",
    "            bs = b[0]\n",
    "            be = b[0] + b[1]\n",
    "            for i in range(bs, be):            \n",
    "                profile = [user.artwork_idxs[j] for j in range(bs, be) if j != i]\n",
    "                assert len(profile) == be - bs - 1\n",
    "                assert len(profile) > 0\n",
    "                \n",
    "                pi = user.artwork_idxs[i]\n",
    "                \n",
    "                # train instances\n",
    "                for _ in range(n_neg_per_pos):\n",
    "                    ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.55)\n",
    "                    append_instance(train_instances, (profile, pi, ni, ui))\n",
    "                    \n",
    "                # test instance\n",
    "                ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.55)\n",
    "                append_instance(test_instances, (profile, pi, ni, ui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(694190, 42850)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_samples__given_present_hide_rank_one(n_neg_per_pos=35)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Given the past and the present, hide one and rank it higher than any item of non-purchased artists as long as ResNet50 doesn't disagree by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_present_hide_rank_one(n_neg_per_pos=3):\n",
    "    for ui, user in enumerate(users):\n",
    "        if (len(user.baskets) < 2):\n",
    "            continue\n",
    "        u_baskets = user.baskets\n",
    "        u_artwork_idxs = user.artwork_idxs\n",
    "        n_baskets = len(u_baskets)\n",
    "        purchased = []\n",
    "        for i in range(n_baskets):\n",
    "            b = u_baskets[i]\n",
    "            purchased.extend(u_artwork_idxs[j] for j in range(b[0], b[0] + b[1]))\n",
    "            if i == 0:\n",
    "                continue\n",
    "            assert len(purchased) == b[0] + b[1]\n",
    "            jmax = b[0] + (b[1] if b[1] >= 2 else 0)\n",
    "            for j in range(jmax):\n",
    "                \n",
    "                profile = [x for k,x in enumerate(purchased) if k != j]\n",
    "                \n",
    "                pi = u_artwork_idxs[j]\n",
    "                \n",
    "                # train instances\n",
    "                for _ in range(n_neg_per_pos):\n",
    "                    ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.55)\n",
    "                    append_instance(train_instances, (profile, pi, ni, ui))\n",
    "                    \n",
    "                # test instance\n",
    "                ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.55)\n",
    "                append_instance(test_instances, (profile, pi, ni, ui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816197, 83519)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_samples__given_past_present_hide_rank_one(n_neg_per_pos=3)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort train and test instances by profile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances.sort(key=lambda x: len(x[0]))\n",
    "test_instances.sort(key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Tensorflow Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, learning_rate=1e-4):\n",
    "        \n",
    "        print('Network::__init__: learning_rate = ', learning_rate)\n",
    "        \n",
    "        # --- placeholders\n",
    "        self._pretrained_embeddings = tf.placeholder(shape=[None, 2048], dtype=tf.float32,\n",
    "                                                     name='pretrained_embeddings')            \n",
    "        self._profile_item_indexes = tf.placeholder(shape=[None,None], dtype=tf.int32,\n",
    "                                                    name='profile_item_indexes')\n",
    "        self._profile_sizes = tf.placeholder(shape=[None], dtype=tf.float32,\n",
    "                                                   name='profile_sizes')        \n",
    "        self._positive_item_index = tf.placeholder(shape=[None], dtype=tf.int32,\n",
    "                                                   name='positive_item_index')\n",
    "        self._negative_item_index = tf.placeholder(shape=[None], dtype=tf.int32,\n",
    "                                                   name='negative_item_index')\n",
    "            \n",
    "        # ---- user profile vector\n",
    "        \n",
    "        # profile item embeddings average\n",
    "        tmp = tf.gather(self._pretrained_embeddings, self._profile_item_indexes)\n",
    "        self._profile_item_embeddings = self.trainable_item_embedding(tmp)\n",
    "        self._profile_masks = tf.expand_dims(tf.sequence_mask(self._profile_sizes, dtype=tf.float32), -1)\n",
    "        self._masked_profile_item_embeddings = tf.multiply(self._profile_item_embeddings, self._profile_masks)        \n",
    "        self._profile_items_average =\\\n",
    "            tf.reduce_sum(self._masked_profile_item_embeddings, axis=1) /\\\n",
    "            tf.reshape(self._profile_sizes, [-1, 1])\n",
    "            \n",
    "        # user hidden layer\n",
    "        self._user_hidden = tf.layers.dense(\n",
    "            inputs=self._profile_items_average,\n",
    "            units=128,\n",
    "            activation=tf.nn.selu,\n",
    "            name='user_hidden'\n",
    "        )\n",
    "        \n",
    "        # user final vector\n",
    "        self._user_vector = tf.layers.dense(\n",
    "            inputs=self._user_hidden,\n",
    "            units=128,\n",
    "            activation=tf.nn.selu,\n",
    "            name='user_vector'\n",
    "        )\n",
    "        \n",
    "        # ---- positive item vector\n",
    "        tmp = tf.gather(self._pretrained_embeddings, self._positive_item_index)\n",
    "        self._positive_item_vector = self.trainable_item_embedding(tmp)\n",
    "        \n",
    "        # ---- negative item vector\n",
    "        tmp = tf.gather(self._pretrained_embeddings, self._negative_item_index)\n",
    "        self._negative_item_vector = self.trainable_item_embedding(tmp)\n",
    "        \n",
    "        # --- train loss\n",
    "        dot_pos = tf.reduce_sum(tf.multiply(self._user_vector, self._positive_item_vector), 1)\n",
    "        dot_neg = tf.reduce_sum(tf.multiply(self._user_vector, self._negative_item_vector), 1)\n",
    "        dot_delta = dot_pos - dot_neg\n",
    "        ones = tf.fill(tf.shape(self._user_vector)[:1], 1.0)\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=dot_delta, labels=ones)\n",
    "        loss = tf.reduce_mean(loss, name='train_loss')\n",
    "        self._train_loss = loss\n",
    "        \n",
    "        # --- test accuracy\n",
    "        accuracy = tf.reduce_sum(tf.cast(dot_delta > .0, tf.float32), name = 'test_accuracy')\n",
    "        self._test_accuracy = accuracy\n",
    "        \n",
    "        # --- optimizer\n",
    "        self._optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self._train_loss)\n",
    "        \n",
    "    @staticmethod\n",
    "    def trainable_item_embedding(X):\n",
    "        with tf.variable_scope(\"trainable_item_embedding\", reuse=tf.AUTO_REUSE):\n",
    "            fc1 = tf.layers.dense( # None -> 256\n",
    "                inputs=X,\n",
    "                units=256,\n",
    "                activation=tf.nn.selu,\n",
    "                name='fc1'\n",
    "            )\n",
    "            fc2 = tf.layers.dense( # 256 -> 128\n",
    "                inputs=fc1,\n",
    "                units=128,\n",
    "                activation=tf.nn.selu,\n",
    "                name='fc2'\n",
    "            )\n",
    "            return fc2\n",
    "    \n",
    "    def optimize_and_get_train_loss(self, sess, pretrained_embeddings, profile_item_indexes, profile_sizes,\n",
    "             positive_item_index, negative_item_index):\n",
    "        return sess.run([\n",
    "            self._optimizer,\n",
    "            self._train_loss,\n",
    "        ], feed_dict={\n",
    "            self._pretrained_embeddings: pretrained_embeddings,\n",
    "            self._profile_item_indexes: profile_item_indexes,\n",
    "            self._profile_sizes: profile_sizes,\n",
    "            self._positive_item_index: positive_item_index,\n",
    "            self._negative_item_index: negative_item_index,\n",
    "        })\n",
    "    \n",
    "    def get_train_loss(self, sess, pretrained_embeddings, profile_item_indexes, profile_sizes,\n",
    "             positive_item_index, negative_item_index):\n",
    "        return sess.run(\n",
    "            self._train_loss, feed_dict={\n",
    "            self._pretrained_embeddings: pretrained_embeddings,\n",
    "            self._profile_item_indexes: profile_item_indexes,\n",
    "            self._profile_sizes: profile_sizes,\n",
    "            self._positive_item_index: positive_item_index,\n",
    "            self._negative_item_index: negative_item_index,\n",
    "        })\n",
    "    \n",
    "    def get_test_accuracy(self, sess, pretrained_embeddings, profile_item_indexes, profile_sizes,\n",
    "             positive_item_index, negative_item_index):\n",
    "        return sess.run(\n",
    "            self._test_accuracy, feed_dict={\n",
    "            self._pretrained_embeddings: pretrained_embeddings,\n",
    "            self._profile_item_indexes: profile_item_indexes,\n",
    "            self._profile_sizes: profile_sizes,\n",
    "            self._positive_item_index: positive_item_index,\n",
    "            self._negative_item_index: negative_item_index,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network::__init__: learning_rate =  0.0001\n"
     ]
    }
   ],
   "source": [
    "# DEBUGGING \n",
    "# with tf.Graph().as_default():\n",
    "#     network = Network()\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         tmp_debug = sess.run([\n",
    "#             network._profile_item_embeddings,\n",
    "#             network._profile_masks,\n",
    "#             network._masked_profile_item_embeddings,\n",
    "#             network._profile_items_average,\n",
    "#         ], feed_dict={\n",
    "#             network._pretrained_embeddings: resnet50_embeddings,\n",
    "#             network._profile_item_indexes: [[0, 1], [2, 3]],\n",
    "#             network._profile_sizes: [1, 2],\n",
    "#         })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatches(tuples, batch_size):\n",
    "    n_tuples = len(tuples)\n",
    "    n_batches = (n_tuples // batch_size) + int(n_tuples % batch_size > 0)\n",
    "    \n",
    "    print('n_tuples = ', n_tuples)\n",
    "    print('n_batches = ', n_batches)\n",
    "    \n",
    "    profile_indexes_batches = [None] * n_batches\n",
    "    profile_size_batches = [None] * n_batches\n",
    "    positive_index_batches = [None] * n_batches\n",
    "    negative_index_batches = [None] * n_batches\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        jmin = i * batch_size\n",
    "        jmax = min(jmin + batch_size, n_tuples)\n",
    "        actual_batch_size = jmax - jmin\n",
    "        \n",
    "        profile_maxlen = max(len(tuples[j][0]) for j in range(jmin, jmax))\n",
    "        profile_indexes_batch = np.full((actual_batch_size, profile_maxlen), 0, dtype=int)\n",
    "        profile_size_batch = np.empty((actual_batch_size,))\n",
    "        positive_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        negative_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        \n",
    "        for j in range(actual_batch_size):            \n",
    "            # profile indexes\n",
    "            for k,v in enumerate(tuples[jmin+j][0]):\n",
    "                profile_indexes_batch[j][k] = v\n",
    "            # profile size\n",
    "            profile_size_batch[j] = len(tuples[jmin+j][0])        \n",
    "            # positive index\n",
    "            positive_index_batch[j] = tuples[jmin+j][1]\n",
    "            # negative index\n",
    "            negative_index_batch[j] = tuples[jmin+j][2]\n",
    "            \n",
    "        profile_indexes_batches[i] = profile_indexes_batch\n",
    "        profile_size_batches[i] = profile_size_batch\n",
    "        positive_index_batches[i] = positive_index_batch\n",
    "        negative_index_batches[i] = negative_index_batch\n",
    "        \n",
    "    return dict(\n",
    "        profile_indexes_batches = profile_indexes_batches,\n",
    "        profile_size_batches    = profile_size_batches,\n",
    "        positive_index_batches  = positive_index_batches,\n",
    "        negative_index_batches  = negative_index_batches,\n",
    "        n_batches               = n_batches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_minibatches(minibatches):\n",
    "    for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "        minibatches['profile_indexes_batches'],\n",
    "        minibatches['profile_size_batches'],\n",
    "        minibatches['positive_index_batches'],\n",
    "        minibatches['negative_index_batches']\n",
    "    ):\n",
    "        n = profile_size.shape[0]\n",
    "        assert n == profile_indexes.shape[0]\n",
    "        assert n == positive_index.shape[0]\n",
    "        assert n == negative_index.shape[0]\n",
    "        \n",
    "        for i in range(n):\n",
    "            assert positive_index[i] != negative_index[i]\n",
    "            psz = int(profile_size[i])\n",
    "            m = profile_indexes[i].shape[0]\n",
    "            assert psz <= m\n",
    "            for j in range(psz, m):\n",
    "                assert profile_indexes[i][j] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/mnt/workspace/pamessina_models/ugallery/youtube_like/v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(train_instances, test_instances, batch_size=64, max_epochs=60,\n",
    "                  learning_rate=1e-4, early_stopping_epochs=4, session_config=None):\n",
    "    \n",
    "    train_minibatches = generate_minibatches(train_instances, batch_size)\n",
    "    test_minibatches = generate_minibatches(test_instances, batch_size)    \n",
    "    sanity_check_minibatches(train_minibatches)\n",
    "    sanity_check_minibatches(test_minibatches)\n",
    "    n_train_batches = train_minibatches['n_batches']\n",
    "    n_test_batches = test_minibatches['n_batches']\n",
    "    n_test_instances = len(test_instances)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        network = Network(learning_rate=learning_rate)\n",
    "        with tf.Session(config=session_config) as sess:\n",
    "            try:\n",
    "                saver = tf.train.Saver()            \n",
    "                saver.restore(sess, tf.train.latest_checkpoint(MODEL_PATH))\n",
    "                print('model successfully restored from checkpoint!')\n",
    "            except ValueError:\n",
    "                print('no checkpoint found: initializing variables with random values')\n",
    "                os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # ========= BEFORE TRAINING ============\n",
    "            \n",
    "            initial_test_acc = 0.\n",
    "            for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                test_minibatches['profile_indexes_batches'],\n",
    "                test_minibatches['profile_size_batches'],\n",
    "                test_minibatches['positive_index_batches'],\n",
    "                test_minibatches['negative_index_batches']\n",
    "            ):\n",
    "                minibatch_test_acc = network.get_test_accuracy(\n",
    "                    sess, resnet50_embeddings, profile_indexes, profile_size, positive_index, negative_index)\n",
    "                initial_test_acc += minibatch_test_acc\n",
    "            initial_test_acc = (initial_test_acc / n_test_instances) * 100.\n",
    "\n",
    "            print(\"Before training: test_accuracy = %f%%\" % initial_test_acc)\n",
    "            \n",
    "            best_test_acc = initial_test_acc\n",
    "            last_improvement_epoch = -1\n",
    "            last_improvement_epoch_train_loss = None\n",
    "\n",
    "            # ========= TRAINING ============\n",
    "            \n",
    "            print ('Starting training ...')\n",
    "\n",
    "            for epoch in range(max_epochs):\n",
    "                \n",
    "                start_time = time.time()\n",
    "\n",
    "                # --- training\n",
    "                epoch_train_loss = 0.\n",
    "                for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                    train_minibatches['profile_indexes_batches'],\n",
    "                    train_minibatches['profile_size_batches'],\n",
    "                    train_minibatches['positive_index_batches'],\n",
    "                    train_minibatches['negative_index_batches']\n",
    "                ):\n",
    "                    _, minibatch_train_loss = network.optimize_and_get_train_loss(\n",
    "                        sess, resnet50_embeddings, profile_indexes, profile_size, positive_index, negative_index)                \n",
    "                    epoch_train_loss += minibatch_train_loss\n",
    "                epoch_train_loss /= n_train_batches\n",
    "\n",
    "                # --- testing\n",
    "                epoch_test_acc = 0.\n",
    "                for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                    test_minibatches['profile_indexes_batches'],\n",
    "                    test_minibatches['profile_size_batches'],\n",
    "                    test_minibatches['positive_index_batches'],\n",
    "                    test_minibatches['negative_index_batches']\n",
    "                ):\n",
    "                    minibatch_test_acc = network.get_test_accuracy(\n",
    "                        sess, resnet50_embeddings, profile_indexes, profile_size, positive_index, negative_index)\n",
    "                    epoch_test_acc += minibatch_test_acc\n",
    "                epoch_test_acc = (epoch_test_acc / n_test_instances) * 100.\n",
    "                \n",
    "                elapsed_seconds = time.time() - start_time\n",
    "                \n",
    "                # --- check for improvements and update best model if necessary\n",
    "                print(\"epoch %d: train_loss = %f, test_accuracy = %f%%, elapsed_seconds = %f\" % (\n",
    "                        epoch, epoch_train_loss, epoch_test_acc, elapsed_seconds))                \n",
    "                if (epoch_test_acc > best_test_acc) or (\n",
    "                    epoch_test_acc == best_test_acc and (\n",
    "                        last_improvement_epoch_train_loss is not None and\\\n",
    "                        epoch_train_loss < last_improvement_epoch_train_loss\n",
    "                    )\n",
    "                ):\n",
    "                    saver = tf.train.Saver()\n",
    "                    save_path = saver.save(sess, MODEL_PATH)\n",
    "                    best_test_acc = epoch_test_acc\n",
    "                    last_improvement_epoch = epoch\n",
    "                    last_improvement_epoch_train_loss = epoch_train_loss\n",
    "                    print(\"   ** improvement detected: model saved to path \", save_path)\n",
    "                else:                    \n",
    "                    if (epoch - last_improvement_epoch >= early_stopping_epochs):\n",
    "                        print(\"   *** %d epochs with no improvements -> early stopping :(\" % early_stopping_epochs)\n",
    "                        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  816197\n",
      "n_batches =  545\n",
      "n_tuples =  83519\n",
      "n_batches =  56\n",
      "Network::__init__: learning_rate =  1e-06\n",
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/pamessina_models/ugallery/youtube_like/v1/\n",
      "model successfully restored from checkpoint!\n",
      "Before training: test_accuracy = 99.261246%\n",
      "Starting training ...\n",
      "epoch 0: train_loss = 0.000027, test_accuracy = 99.263641%, elapsed_seconds = 75.409202\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v1/\n",
      "epoch 1: train_loss = 0.000026, test_accuracy = 99.267233%, elapsed_seconds = 75.264133\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v1/\n",
      "epoch 2: train_loss = 0.000025, test_accuracy = 99.264838%, elapsed_seconds = 75.024105\n",
      "epoch 3: train_loss = 0.000024, test_accuracy = 99.262443%, elapsed_seconds = 75.121038\n",
      "epoch 4: train_loss = 0.000023, test_accuracy = 99.263641%, elapsed_seconds = 75.021706\n",
      "epoch 5: train_loss = 0.000022, test_accuracy = 99.264838%, elapsed_seconds = 75.046028\n",
      "epoch 6: train_loss = 0.000021, test_accuracy = 99.263641%, elapsed_seconds = 75.145068\n",
      "   *** 5 epochs with no improvements -> early stopping :(\n"
     ]
    }
   ],
   "source": [
    "train_network(train_instances, test_instances, batch_size=1500, max_epochs=60, learning_rate=1e-6, early_stopping_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
