{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from os import path\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load pre-trained ResNet50 image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_and_ids(dirpath, embedding_file, ids_file):\n",
    "    embeddings = np.load(path.join(dirpath, embedding_file))\n",
    "    with open(path.join(dirpath, ids_file)) as f:\n",
    "        ids = [int(x) for x in f.readlines()]\n",
    "        id2index = { _id:i for i,_id in enumerate(ids) }    \n",
    "    assert (embeddings.shape[0] == len(ids))\n",
    "    return embeddings, ids, id2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_embeddings,\\\n",
    "resnet50_ids,\\\n",
    "resnet50_id2index = load_embeddings_and_ids(\n",
    "'/mnt/workspace/Ugallery/ResNet50/', 'flatten_1.npy', 'ids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load UGallery transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('./valid_sales.csv')\n",
    "artworks_df = pd.read_csv('./valid_artworks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "artwork_ids = list(artworks_df.id)\n",
    "artwork_id_2_index = { _id:i+1 for i,_id in enumerate(artwork_ids) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_artworks = len(artwork_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_ids = list(artworks_df.artist_id)\n",
    "artwork_id_2_artist_id = {i:j for i,j in zip(artwork_ids, artist_ids)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  reduce embedding matrix to only rows of artworks appearing in transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((n_artworks + 1, 2048))\n",
    "for i, _id in enumerate(artwork_ids):\n",
    "    embeddings[i+1] = resnet50_embeddings[resnet50_id2index[_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7742"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert(n_artworks + 1 == embeddings.shape[0])\n",
    "n_artworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect transactions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, uid):\n",
    "        self._uid = uid\n",
    "        self.artwork_ids = []\n",
    "        self.artwork_idxs = []\n",
    "        self.artwork_idxs_set = set()\n",
    "        self.timestamps = []\n",
    "        self.artist_ids = set()\n",
    "        \n",
    "    def clear(self):\n",
    "        self.artwork_ids.clear()\n",
    "        self.artwork_idxs.clear()\n",
    "        self.artwork_idxs_set.clear()\n",
    "        self.timestamps.clear()\n",
    "        self.artist_ids.clear()\n",
    "        \n",
    "    def append_transaction(self, artwork_id, timestamp):\n",
    "        self.artwork_ids.append(artwork_id)\n",
    "        self.artwork_idxs.append(artwork_id_2_index[artwork_id])\n",
    "        self.artwork_idxs_set.add(artwork_id_2_index[artwork_id])\n",
    "        self.timestamps.append(timestamp)\n",
    "        \n",
    "    def build_purchase_baskets(self):\n",
    "        baskets = []\n",
    "        prev_t = None\n",
    "        offset = 0\n",
    "        count = 0\n",
    "        for i, t in enumerate(self.timestamps):\n",
    "            if t != prev_t:\n",
    "                if prev_t is not None:\n",
    "                    baskets.append((offset, count))\n",
    "                    offset = i\n",
    "                count = 1\n",
    "            else:\n",
    "                count += 1\n",
    "            prev_t = t\n",
    "        baskets.append((offset, count))\n",
    "        self.baskets = baskets\n",
    "        \n",
    "    def sanity_check_purchase_baskets(self):\n",
    "        ids = self.artwork_ids\n",
    "        ts = self.timestamps\n",
    "        baskets = self.baskets\n",
    "        assert(len(ids) == len(ts))\n",
    "        n = len(ts)\n",
    "        assert (n > 0)\n",
    "        for b in baskets:\n",
    "            for j in range(b[0], b[0] + b[1] - 1):\n",
    "                assert(ts[j] == ts[j+1])\n",
    "        for i in range(1, len(baskets)):\n",
    "            b1 = baskets[i-1]\n",
    "            b2 = baskets[i]\n",
    "            assert(b1[0] + b1[1] == b2[0])\n",
    "        assert(baskets[0][0] == 0)\n",
    "        assert(baskets[-1][0] + baskets[-1][1] == n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = sales_df.customer_id.unique()\n",
    "user_id_2_index = { _id:i for i,_id in enumerate(user_ids) }\n",
    "n_users = len(user_ids)\n",
    "users = [User(uid) for uid in user_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect and sanitiy check transactions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sales_df = sales_df.sort_values('order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear structures to prevent possible duplicate elements\n",
    "for user in users:\n",
    "    user.clear()\n",
    "\n",
    "# collect transactions per user sorted by timestamp\n",
    "for uid, aid, t in zip(sorted_sales_df.customer_id,\n",
    "                       sorted_sales_df.artwork_id,\n",
    "                       sorted_sales_df.order_date):\n",
    "    i = user_id_2_index[uid]\n",
    "    users[i].append_transaction(aid,t)\n",
    "    users[i].artist_ids.add(artwork_id_2_artist_id[aid])\n",
    "    \n",
    "# bin transctions with same timestamps into purchase baskets\n",
    "for user in users:\n",
    "    user.build_purchase_baskets()\n",
    "    user.sanity_check_purchase_baskets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 6\n",
    "# users[x].artwork_ids,\\\n",
    "# users[x].timestamps,\\\n",
    "# users[x].baskets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Top K most disimilar images not sharing artists for each user\n",
    "#### (to draw negative samples from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat = squareform(pdist(embeddings, 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [00:27<00:00, 105.54it/s]\n"
     ]
    }
   ],
   "source": [
    "TOPK = 40\n",
    "for user in tqdm(users):\n",
    "    u_artwork_idxs = user.artwork_idxs\n",
    "    u_artist_ids = user.artist_ids\n",
    "    h = []\n",
    "    for artwork_id, artist_id in zip(artwork_ids, artist_ids):        \n",
    "        if artist_id in u_artist_ids:\n",
    "            continue\n",
    "        i = artwork_id_2_index[artwork_id]\n",
    "        score = min(distmat[i][j] for j in u_artwork_idxs)\n",
    "        if (len(h) < TOPK):\n",
    "            heapq.heappush(h, (score, i))\n",
    "        else:\n",
    "            heapq.heappushpop(h, (score, i))\n",
    "    assert(len(h) == TOPK)\n",
    "    user.negative_idxs = [i for _,i in h]\n",
    "    user.negative_idxs_set = set(user.negative_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_data(data):\n",
    "    for t in data:\n",
    "        profile = t[0]\n",
    "        pos = t[1]\n",
    "        neg = t[2]\n",
    "        user = users[t[3]]\n",
    "        try:\n",
    "            assert all(i in user.artwork_idxs_set for i in profile)\n",
    "            assert pos in user.artwork_idxs_set\n",
    "            assert neg not in user.artwork_idxs_set\n",
    "            assert artwork_id_2_artist_id[artwork_ids[neg-1]] not in user.artist_ids\n",
    "            assert neg in user.negative_idxs_set\n",
    "        except AssertionError:\n",
    "            print(t)\n",
    "            print(user._uid)\n",
    "            print(user.artwork_idxs)\n",
    "            print(user.artwork_idxs_set)\n",
    "            print(user.negative_idxs)\n",
    "            print(user.negative_idxs_set)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Given the past, rank higher each one of next purchase basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_rank_next(n_neg):\n",
    "    for ui, user in tqdm(enumerate(users)):\n",
    "        past_items = []\n",
    "        n = len(user.baskets)\n",
    "        for i in range(n-1):\n",
    "            cur_b = user.baskets[i]        \n",
    "            for j in range(cur_b[0], cur_b[0] + cur_b[1]):\n",
    "                past_items.append(user.artwork_idxs[j])\n",
    "            next_b  = user.baskets[i+1]\n",
    "            profile = past_items.copy()\n",
    "            for pi in range(next_b[0], next_b[0] + next_b[1]):\n",
    "                neg = random.sample(user.negative_idxs, n_neg+1)\n",
    "                p = user.artwork_idxs[pi]\n",
    "                for k in range(n_neg):\n",
    "                    train_instances.append((profile, p, neg[k], ui))\n",
    "                test_instances.append((profile, p, neg[-1], ui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2919it [00:00, 121128.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15984, 2664)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_samples__given_past_rank_next(n_neg=6)\n",
    "sanity_check_data(train_instances)\n",
    "sanity_check_data(test_instances)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Given only the present, hide one and rank it higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_present_hide_rank_one(n_neg):\n",
    "    for ui, user in tqdm(enumerate(users)):\n",
    "        for b in user.baskets:\n",
    "            if b[1] < 2:\n",
    "                continue\n",
    "            bs = b[0]\n",
    "            be = b[0] + b[1]\n",
    "            for i in range(bs, be):            \n",
    "                profile = [user.artwork_idxs[j] for j in range(bs, be) if j != i]\n",
    "                pi = user.artwork_idxs[i]            \n",
    "                neg = random.sample(user.negative_idxs, n_neg+1)\n",
    "                for j in range(n_neg):\n",
    "                    train_instances.append((profile, pi, neg[j], ui))\n",
    "                test_instances.append((profile, pi, neg[-1], ui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2919it [00:00, 128959.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31116, 5186)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_samples__given_present_hide_rank_one(n_neg=6)\n",
    "sanity_check_data(train_instances)\n",
    "sanity_check_data(test_instances)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Given the past and the present, hide one and rank it higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_present_hide_rank_one(n_neg):\n",
    "    for ui, user in tqdm(enumerate(users)):\n",
    "        if (len(user.baskets) < 2):\n",
    "            continue\n",
    "        u_baskets = user.baskets\n",
    "        u_artwork_idxs = user.artwork_idxs\n",
    "        n = len(u_baskets)\n",
    "        purchased = []\n",
    "        for i in range(n):\n",
    "            b = u_baskets[i]\n",
    "            purchased.extend(u_artwork_idxs[j] for j in range(b[0], b[0] + b[1]))\n",
    "            if i == 0:\n",
    "                continue        \n",
    "            assert len(purchased) == b[0] + b[1]\n",
    "            jmax = b[0] + (b[1] if b[1] >= 2 else 0)\n",
    "            for j in range(jmax):\n",
    "                profile = [x for k,x in enumerate(purchased) if k != j]\n",
    "                p = u_artwork_idxs[j]\n",
    "                neg = random.sample(user.negative_idxs, n_neg+1)\n",
    "                for k in range(n_neg):\n",
    "                    train_instances.append((profile, p, neg[k], ui))\n",
    "                test_instances.append((profile, p, neg[-1], ui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2919it [00:00, 6480.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(153123, 45855)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_samples__given_past_present_hide_rank_one(3)\n",
    "sanity_check_data(train_instances)\n",
    "sanity_check_data(test_instances)\n",
    "len(train_instances), len(test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort train and test instances by profile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances.sort(key=lambda x: len(x[0]))\n",
    "test_instances.sort(key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Tensorflow Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # --- placeholders\n",
    "        self._pretrained_embeddings = tf.placeholder(shape=[None, 2048], dtype=tf.float32,\n",
    "                                                     name='pretrained_embeddings')            \n",
    "        self._profile_item_indexes = tf.placeholder(shape=[None,None], dtype=tf.int32,\n",
    "                                                    name='profile_item_indexes')\n",
    "        self._profile_item_counts = tf.placeholder(shape=[None], dtype=tf.float32,\n",
    "                                                   name='profile_item_counts')\n",
    "        self._positive_item_index = tf.placeholder(shape=[None], dtype=tf.int32,\n",
    "                                                   name='positive_item_index')\n",
    "        self._negative_item_index = tf.placeholder(shape=[None], dtype=tf.int32,\n",
    "                                                   name='negative_item_index')\n",
    "            \n",
    "        # ---- user profile vector\n",
    "        # profile item embeddings average\n",
    "        tmp = tf.gather(self._pretrained_embeddings, self._profile_item_indexes)\n",
    "        self._profile_item_embeddings = self.trainable_item_embedding(tmp)        \n",
    "        self._profile_items_average =\\\n",
    "            tf.reduce_sum(self._profile_item_embeddings, axis=1) /\\\n",
    "            tf.reshape(self._profile_item_counts, [-1, 1])\n",
    "        # user hidden layer\n",
    "        self._user_hidden = tf.layers.dense(\n",
    "            inputs=self._profile_items_average,\n",
    "            units=128,\n",
    "            activation=tf.nn.selu,\n",
    "            name='user_hidden'\n",
    "        )\n",
    "        # user final vector\n",
    "        self._user_vector = tf.layers.dense(\n",
    "            inputs=self._user_hidden,\n",
    "            units=128,\n",
    "            activation=tf.nn.selu,\n",
    "            name='user_vector'\n",
    "        )\n",
    "        \n",
    "        # ---- positive item vector\n",
    "        tmp = tf.gather(self._pretrained_embeddings, self._positive_item_index)\n",
    "        self._positive_item_vector = self.trainable_item_embedding(tmp)\n",
    "        \n",
    "        # ---- negative item vector\n",
    "        tmp = tf.gather(self._pretrained_embeddings, self._negative_item_index)\n",
    "        self._negative_item_vector = self.trainable_item_embedding(tmp)\n",
    "        \n",
    "        # --- train loss\n",
    "        dot_pos = tf.reduce_sum(tf.multiply(self._user_vector, self._positive_item_vector), 1)\n",
    "        dot_neg = tf.reduce_sum(tf.multiply(self._user_vector, self._negative_item_vector), 1)\n",
    "        dot_delta = dot_pos - dot_neg\n",
    "        ones = tf.fill(tf.shape(self._user_vector)[:1], 1.0)\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=dot_delta, labels=ones)\n",
    "        loss = tf.reduce_mean(loss, name='train_loss')\n",
    "        self._train_loss = loss\n",
    "        \n",
    "        # --- test loss\n",
    "        loss = tf.reduce_sum(tf.cast(dot_delta <= .0, tf.float32), name = 'test_loss')\n",
    "        self._test_loss = loss\n",
    "        \n",
    "        # --- optimizer\n",
    "        self._optimizer = tf.train.AdamOptimizer(0.2e-5).minimize(self._train_loss)\n",
    "        \n",
    "    @staticmethod\n",
    "    def trainable_item_embedding(X):\n",
    "        with tf.variable_scope(\"trainable_item_embedding\", reuse=tf.AUTO_REUSE):\n",
    "            fc1 = tf.layers.dense( # None -> 256\n",
    "                inputs=X,\n",
    "                units=256,\n",
    "                activation=tf.nn.selu,\n",
    "                name='fc1'\n",
    "            )\n",
    "            fc2 = tf.layers.dense( # 256 -> 128\n",
    "                inputs=fc1,\n",
    "                units=128,\n",
    "                activation=tf.nn.selu,\n",
    "                name='fc2'\n",
    "            )\n",
    "            return fc2\n",
    "    \n",
    "    def optimize_and_get_train_loss(self, sess, pretrained_embeddings, profile_item_indexes, profile_item_counts,\n",
    "             positive_item_index, negative_item_index):\n",
    "        return sess.run([\n",
    "            self._optimizer,\n",
    "            self._train_loss,\n",
    "        ], feed_dict={\n",
    "            self._pretrained_embeddings: pretrained_embeddings,\n",
    "            self._profile_item_indexes: profile_item_indexes,\n",
    "            self._profile_item_counts: profile_item_counts,\n",
    "            self._positive_item_index: positive_item_index,\n",
    "            self._negative_item_index: negative_item_index,\n",
    "        })\n",
    "    \n",
    "    def get_train_loss(self, sess, pretrained_embeddings, profile_item_indexes, profile_item_counts,\n",
    "             positive_item_index, negative_item_index):\n",
    "        return sess.run(\n",
    "            self._train_loss, feed_dict={\n",
    "            self._pretrained_embeddings: pretrained_embeddings,\n",
    "            self._profile_item_indexes: profile_item_indexes,\n",
    "            self._profile_item_counts: profile_item_counts,\n",
    "            self._positive_item_index: positive_item_index,\n",
    "            self._negative_item_index: negative_item_index,\n",
    "        })\n",
    "    \n",
    "    def get_test_loss(self, sess, pretrained_embeddings, profile_item_indexes, profile_item_counts,\n",
    "             positive_item_index, negative_item_index):\n",
    "        return sess.run(\n",
    "            self._test_loss, feed_dict={\n",
    "            self._pretrained_embeddings: pretrained_embeddings,\n",
    "            self._profile_item_indexes: profile_item_indexes,\n",
    "            self._profile_item_counts: profile_item_counts,\n",
    "            self._positive_item_index: positive_item_index,\n",
    "            self._negative_item_index: negative_item_index,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatches(tuples, batch_size):\n",
    "    n_tuples = len(tuples)\n",
    "    n_batches = (n_tuples // batch_size) + int(n_tuples % batch_size > 0)\n",
    "    \n",
    "    print('n_tuples = ', n_tuples)\n",
    "    print('n_batches = ', n_batches)\n",
    "    \n",
    "    profile_indexes_batches = [None] * n_batches\n",
    "    profile_size_batches = [None] * n_batches\n",
    "    positive_index_batches = [None] * n_batches\n",
    "    negative_index_batches = [None] * n_batches\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        jmin = i * batch_size\n",
    "        jmax = min(jmin + batch_size, n_tuples)\n",
    "        actual_batch_size = jmax - jmin\n",
    "        \n",
    "        profile_maxlen = max(len(tuples[j][0]) for j in range(jmin, jmax))\n",
    "        profile_indexes_batch = np.zeros((actual_batch_size, profile_maxlen), dtype=int)\n",
    "        profile_size_batch = np.empty((actual_batch_size,))\n",
    "        positive_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        negative_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        \n",
    "        for j in range(actual_batch_size):            \n",
    "            # profile indexes\n",
    "            for k,v in enumerate(tuples[jmin+j][0]):\n",
    "                profile_indexes_batch[j][k] = v\n",
    "            # profile size\n",
    "            profile_size_batch[j] = len(tuples[jmin+j][0])        \n",
    "            # positive index\n",
    "            positive_index_batch[j] = tuples[jmin+j][1]\n",
    "            # negative index\n",
    "            negative_index_batch[j] = tuples[jmin+j][2]\n",
    "            \n",
    "        profile_indexes_batches[i] = profile_indexes_batch\n",
    "        profile_size_batches[i] = profile_size_batch\n",
    "        positive_index_batches[i] = positive_index_batch\n",
    "        negative_index_batches[i] = negative_index_batch\n",
    "        \n",
    "    return dict(\n",
    "        profile_indexes_batches = profile_indexes_batches,\n",
    "        profile_size_batches    = profile_size_batches,\n",
    "        positive_index_batches  = positive_index_batches,\n",
    "        negative_index_batches  = negative_index_batches,\n",
    "        n_batches               = n_batches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_minibatches(minibatches):\n",
    "    for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "        minibatches['profile_indexes_batches'],\n",
    "        minibatches['profile_size_batches'],\n",
    "        minibatches['positive_index_batches'],\n",
    "        minibatches['negative_index_batches']\n",
    "    ):\n",
    "        assert all(profile_indexes[i].shape[0] >= profile_size[i] for i in range(profile_size.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/mnt/workspace/pamessina_models/ugallery/youtube_like/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(train_instances, test_instances, batch_size=64, max_epochs=60, session_config=None):\n",
    "    \n",
    "    train_minibatches = generate_minibatches(train_instances, batch_size)\n",
    "    test_minibatches = generate_minibatches(test_instances, batch_size)    \n",
    "    sanity_check_minibatches(train_minibatches)\n",
    "    sanity_check_minibatches(test_minibatches)\n",
    "    n_train_batches = train_minibatches['n_batches']\n",
    "    n_test_batches = test_minibatches['n_batches']\n",
    "    n_test_instances = len(test_instances)\n",
    "    \n",
    "    with tf.Graph().as_default():      \n",
    "        network = Network()  \n",
    "        with tf.Session(config=session_config) as sess:\n",
    "            try:\n",
    "                saver = tf.train.Saver()            \n",
    "                saver.restore(sess, tf.train.latest_checkpoint(MODEL_PATH))\n",
    "                print('model successfully restored from checkpoint!')\n",
    "            except ValueError:\n",
    "                print('no checkpoint found: initializing variables with random values')\n",
    "                os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # ========= BEFORE TRAINING ============\n",
    "            \n",
    "            initial_test_loss = 0.\n",
    "            for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                test_minibatches['profile_indexes_batches'],\n",
    "                test_minibatches['profile_size_batches'],\n",
    "                test_minibatches['positive_index_batches'],\n",
    "                test_minibatches['negative_index_batches']\n",
    "            ):\n",
    "                minibatch_test_loss = network.get_test_loss(\n",
    "                    sess, embeddings, profile_indexes, profile_size, positive_index, negative_index)\n",
    "                initial_test_loss += minibatch_test_loss\n",
    "            initial_test_loss = (initial_test_loss / n_test_instances) * 100.\n",
    "\n",
    "            print(\"Before training: test_loss = %f%%\" % initial_test_loss)\n",
    "            \n",
    "            best_test_loss = initial_test_loss\n",
    "            last_improvement_epoch = -1\n",
    "\n",
    "            # ========= TRAINING ============\n",
    "            \n",
    "            print ('Starting training ...')\n",
    "\n",
    "            for epoch in range(max_epochs):\n",
    "                \n",
    "                start_time = time.time()\n",
    "\n",
    "                # --- training\n",
    "                epoch_train_loss = 0.\n",
    "                for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                    train_minibatches['profile_indexes_batches'],\n",
    "                    train_minibatches['profile_size_batches'],\n",
    "                    train_minibatches['positive_index_batches'],\n",
    "                    train_minibatches['negative_index_batches']\n",
    "                ):\n",
    "                    _, minibatch_train_loss = network.optimize_and_get_train_loss(\n",
    "                        sess, embeddings, profile_indexes, profile_size, positive_index, negative_index)                \n",
    "                    epoch_train_loss += minibatch_train_loss\n",
    "                epoch_train_loss /= n_train_batches\n",
    "\n",
    "                # --- testing\n",
    "                epoch_test_loss = 0.\n",
    "                for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                    test_minibatches['profile_indexes_batches'],\n",
    "                    test_minibatches['profile_size_batches'],\n",
    "                    test_minibatches['positive_index_batches'],\n",
    "                    test_minibatches['negative_index_batches']\n",
    "                ):\n",
    "                    minibatch_test_loss = network.get_test_loss(\n",
    "                        sess, embeddings, profile_indexes, profile_size, positive_index, negative_index)\n",
    "                    epoch_test_loss += minibatch_test_loss\n",
    "                epoch_test_loss = (epoch_test_loss / n_test_instances) * 100.\n",
    "                \n",
    "                elapsed_seconds = time.time() - start_time\n",
    "                \n",
    "                # --- check for improvements and update best model if necessary\n",
    "                print(\"epoch %d: train_loss = %f, test_loss = %f%%, elapsed_seconds = %f\" % (\n",
    "                        epoch, epoch_train_loss, epoch_test_loss, elapsed_seconds))                \n",
    "                if (epoch_test_loss < best_test_loss):\n",
    "                    saver = tf.train.Saver()\n",
    "                    save_path = saver.save(sess, MODEL_PATH)\n",
    "                    best_test_loss = epoch_test_loss\n",
    "                    last_improvement_epoch = epoch\n",
    "                    print(\"   ** improvement detected: model saved to path \", save_path)\n",
    "                else:                    \n",
    "                    if (epoch - last_improvement_epoch >= 6):\n",
    "                        print(\"   *** 6 epochs with no improvements -> early stopping :(\")\n",
    "                        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  153123\n",
      "n_batches =  599\n",
      "n_tuples =  45855\n",
      "n_batches =  180\n",
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/pamessina_models/ugallery/youtube_like/\n",
      "model successfully restored from checkpoint!\n",
      "Before training: test_loss = 0.030531%\n",
      "Starting training ...\n",
      "epoch 0: train_loss = 0.000222, test_loss = 0.028350%, elapsed_seconds = 47.148772\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/\n",
      "epoch 1: train_loss = 0.000016, test_loss = 0.028350%, elapsed_seconds = 47.048991\n",
      "epoch 2: train_loss = 0.000001, test_loss = 0.028350%, elapsed_seconds = 47.054279\n",
      "epoch 3: train_loss = 0.000000, test_loss = 0.028350%, elapsed_seconds = 47.088204\n",
      "epoch 4: train_loss = 0.000000, test_loss = 0.028350%, elapsed_seconds = 47.014436\n",
      "epoch 5: train_loss = 0.000000, test_loss = 0.028350%, elapsed_seconds = 47.044549\n",
      "epoch 6: train_loss = 0.000000, test_loss = 0.026169%, elapsed_seconds = 47.029676\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/\n",
      "epoch 7: train_loss = 0.000000, test_loss = 0.026169%, elapsed_seconds = 47.088580\n",
      "epoch 8: train_loss = 0.000000, test_loss = 0.023989%, elapsed_seconds = 47.089685\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/\n",
      "epoch 9: train_loss = 0.000000, test_loss = 0.023989%, elapsed_seconds = 47.038690\n",
      "epoch 10: train_loss = 0.000000, test_loss = 0.023989%, elapsed_seconds = 47.151519\n",
      "epoch 11: train_loss = 0.000000, test_loss = 0.023989%, elapsed_seconds = 47.059408\n",
      "epoch 12: train_loss = 0.000000, test_loss = 0.023989%, elapsed_seconds = 47.090589\n",
      "epoch 13: train_loss = 0.000000, test_loss = 0.023989%, elapsed_seconds = 47.126290\n",
      "epoch 14: train_loss = 0.000000, test_loss = 0.021808%, elapsed_seconds = 47.010642\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/\n",
      "epoch 15: train_loss = 0.000000, test_loss = 0.021808%, elapsed_seconds = 47.092094\n",
      "epoch 16: train_loss = 0.000000, test_loss = 0.021808%, elapsed_seconds = 47.089526\n",
      "epoch 17: train_loss = 0.000000, test_loss = 0.021808%, elapsed_seconds = 47.100338\n",
      "epoch 18: train_loss = 0.000000, test_loss = 0.021808%, elapsed_seconds = 47.056965\n",
      "epoch 19: train_loss = 0.000000, test_loss = 0.021808%, elapsed_seconds = 47.056454\n",
      "epoch 20: train_loss = 0.000000, test_loss = 0.021808%, elapsed_seconds = 47.106663\n",
      "   *** 6 epochs with no improvements -> early stopping :(\n"
     ]
    }
   ],
   "source": [
    "train_network(train_instances, test_instances, batch_size=256, max_epochs=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
