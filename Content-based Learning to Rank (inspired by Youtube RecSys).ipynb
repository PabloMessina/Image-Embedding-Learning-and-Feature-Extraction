{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport utils, Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from os import path\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from math import ceil, floor\n",
    "from utils import load_embeddings_and_ids, User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a single GPU because we want to be nice with other people :)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load pre-trained ResNet50 image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_embeddings,\\\n",
    "artwork_ids,\\\n",
    "artwork_id2index = load_embeddings_and_ids(\n",
    "'/mnt/workspace/Ugallery/ResNet50/', 'flatten_1.npy', 'ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13297"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_artworks = len(artwork_ids)\n",
    "n_artworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('./valid_sales.csv')\n",
    "artworks_df = pd.read_csv('./valid_artworks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_ids = np.full((n_artworks,), -1, dtype=int)\n",
    "for _artworkId, _artistId in zip(artworks_df.id, artworks_df.artist_id):\n",
    "    i = artwork_id2index[_artworkId]\n",
    "    artist_ids[i] = _artistId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistId2artworkIndexes = dict()\n",
    "for i, _artistId in enumerate(artist_ids):\n",
    "    if _artistId == -1:\n",
    "        continue\n",
    "    try:\n",
    "        artistId2artworkIndexes[_artistId].append(i)\n",
    "    except KeyError:\n",
    "        artistId2artworkIndexes[_artistId] = [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect transactions per user (making sure we hide the last nonfirst purchase basket per user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = sales_df.customer_id.unique()\n",
    "user_id2index = { _id:i for i,_id in enumerate(user_ids) }\n",
    "users = [User(uid) for uid in user_ids]\n",
    "n_users = len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect and sanity check transactions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sales_df = sales_df.sort_values('order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear structures to prevent possible duplicate elements\n",
    "for user in users:\n",
    "    user.clear()\n",
    "\n",
    "# collect transactions per user sorted by timestamp\n",
    "for uid, aid, t in zip(sorted_sales_df.customer_id,\n",
    "                       sorted_sales_df.artwork_id,\n",
    "                       sorted_sales_df.order_date):\n",
    "    users[user_id2index[uid]].append_transaction(aid,t,artwork_id2index,artist_ids)\n",
    "    assert users[user_id2index[uid]]._uid == uid\n",
    "    \n",
    "# bin transctions with same timestamps into purchase baskets\n",
    "for user in users:\n",
    "    user.build_purchase_baskets()\n",
    "    user.sanity_check_purchase_baskets()\n",
    "    user.remove_last_nonfirst_purchase_basket(artwork_id2index, artist_ids)\n",
    "    user.sanity_check_purchase_baskets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute minimun cosine distance from each user profile to each item in the dataset\n",
    "\\* using R200 vectors obtained with PCA(200) over ResNet50 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_PCA200 = PCA(n_components=200).fit_transform(resnet50_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 200)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_PCA200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat = squareform(pdist(resnet50_PCA200, 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2artwork_mindist = np.empty((n_users, n_artworks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [00:41<00:00, 70.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for ui in tqdm(range(n_users)):\n",
    "    for ai in range(n_artworks):\n",
    "        user2artwork_mindist[ui][ai] = min(distmat[ai][j] for j in users[ui].artwork_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash(profile, pi, ni):\n",
    "    h = 0\n",
    "    for x in profile:\n",
    "        h = (h * 127) % 1000000007 + x\n",
    "    h = (h * 127) % 1000000007 + pi\n",
    "    h = (h * 127) % 1000000007 + ni\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_instance(instance, pos_is_purchased=True):\n",
    "    profile, pi, ni, ui = instance\n",
    "    try:\n",
    "        assert 0 <= pi < n_artworks\n",
    "        assert 0 <= ni < n_artworks\n",
    "        assert pi != ni        \n",
    "        if ui == -1:\n",
    "            return # fake user    \n",
    "        assert 0 <= ui < n_users        \n",
    "        user = users[ui]\n",
    "        assert all(i in user.artwork_idxs_set for i in profile)\n",
    "        if pos_is_purchased is not None:\n",
    "            if pos_is_purchased:\n",
    "                assert pi in user.artwork_idxs_set\n",
    "            else:\n",
    "                assert pi not in user.artwork_idxs_set\n",
    "        assert ni not in user.artwork_idxs_set\n",
    "        assert artist_ids[ni] not in user.artist_ids_set\n",
    "    except AssertionError:\n",
    "        print('profile = ', profile)\n",
    "        print('pi = ', pi)\n",
    "        print('ni = ', ni)\n",
    "        print('ui = ', ui)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_instance(container, instance, **kwargs):\n",
    "    global _collisions\n",
    "    h = hash(instance[0], instance[1], instance[2])\n",
    "    if h in used_hashes:\n",
    "        _collisions += 1\n",
    "        return False\n",
    "    sanity_check_instance(instance, **kwargs)\n",
    "    container.append(instance)\n",
    "    used_hashes.add(h)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_hashes = set()\n",
    "_collisions = 0\n",
    "train_instances = []\n",
    "test_instances = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Given a list of purchased items, each purchased item should trivially be ranked higher than any item of non-purchased artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist(profile_artist_ids):\n",
    "    while True:\n",
    "        i = random.randint(0, n_artworks-1)\n",
    "        if artist_ids[i] not in profile_artist_ids:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_above_nonpurchased__real_users(instances_container, n_samples_per_user=600):    \n",
    "    for ui, user in enumerate(users):\n",
    "        profile = user.artwork_idxs\n",
    "        u_artist_ids = user.artist_ids_set        \n",
    "        for _ in range(n_samples_per_user):\n",
    "            for __ in range(5):\n",
    "                pi = random.choice(profile)\n",
    "                ni = sample_artwork_index__notsharingartist(u_artist_ids)                    \n",
    "                if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "1167600 29190\n",
      "collisions =  18873\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_purchased_above_nonpurchased__real_users(train_instances, n_samples_per_user=400)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_purchased_above_nonpurchased__real_users(test_instances, n_samples_per_user=10)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('collisions = ', _collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Given a user, any non-purchased item sharing the same artist with a purchased item should be ranked higher than any item of a non-purchased artist as long as ResNet50 doesn't disagree by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonpurchased_sharingartist(artist_id, artwork_idxs_set):\n",
    "    candidate_idxs = artistId2artworkIndexes[artist_id]\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        i = random.choice(candidate_idxs)\n",
    "        if i not in artwork_idxs_set:\n",
    "            return i\n",
    "    return None # failed to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_user_positive_negative_triplet(ui, pi, ni, threshold=0.55):\n",
    "    dp = user2artwork_mindist[ui][pi]\n",
    "    dn = user2artwork_mindist[ui][ni]    \n",
    "    return (dp + dn) == 0 or dp / (dp + dn) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, threshold):\n",
    "    while True:\n",
    "        ni = sample_artwork_index__notsharingartist(users[ui].artist_ids_set)\n",
    "        if not reject_user_positive_negative_triplet(ui, pi, ni, threshold=threshold):\n",
    "            return ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_artist_above_nonpurchased_artist(instances_container, n_samples_per_user=500):\n",
    "    for ui in range(n_users):\n",
    "        user = users[ui]\n",
    "        profile = user.artwork_idxs\n",
    "        for _ in range(n_samples_per_user):\n",
    "            for __ in range(5):\n",
    "                aid = artist_ids[random.choice(profile)]\n",
    "                assert aid != -1\n",
    "                pi = sample_artwork_index__nonpurchased_sharingartist(aid, user.artwork_idxs_set)\n",
    "                if pi is None:\n",
    "                    continue\n",
    "                ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.55)\n",
    "                if append_instance(instances_container, (profile, pi, ni, ui), pos_is_purchased=False):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "2313736 57841\n",
      "collisions =  27713\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_purchased_artist_above_nonpurchased_artist(train_instances, n_samples_per_user=400)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_purchased_artist_above_nonpurchased_artist(test_instances, n_samples_per_user=10)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('collisions = ', _collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Given all previous purchases, rank each  item of the next purchase basket higher than any item of non-purchased artists as long as ResNet50 doesn't disagree by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_rank_next(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        n = len(user.baskets)\n",
    "        if n <= 1:\n",
    "            continue\n",
    "        past_items = []\n",
    "        n_samples_per_basket = ceil(n_samples_per_user / (n-1))\n",
    "        for i in range(n-1):\n",
    "            cur_b = user.baskets[i]\n",
    "            for j in range(cur_b[0], cur_b[0] + cur_b[1]):\n",
    "                past_items.append(user.artwork_idxs[j])\n",
    "            next_b  = user.baskets[i+1]\n",
    "            profile = past_items.copy()\n",
    "            for _ in range(n_samples_per_basket):\n",
    "                for __ in range(5):\n",
    "                    pi = user.artwork_idxs[random.randint(next_b[0], next_b[0] + next_b[1] - 1)]\n",
    "                    ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.45)\n",
    "                    if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "2922344 88647\n",
      "collisions =  59628\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_past_rank_next(train_instances, n_samples_per_user=1800)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_past_rank_next(test_instances, n_samples_per_user=90)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('collisions = ', _collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Given only the present purchase basket, hide one and rank it higher than any item of non-purchased artists as long as ResNet50 doesn't disagree by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_present_hide_rank_one(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        n = sum(1 if b[1] >=2 else 0 for b in user.baskets)\n",
    "        if n == 0:\n",
    "            continue\n",
    "            \n",
    "        n_samples_per_basket = ceil(n_samples_per_user / n)\n",
    "        for b in user.baskets:\n",
    "            if b[1] < 2:\n",
    "                continue\n",
    "            bs = b[0]\n",
    "            be = b[0] + b[1]\n",
    "            n_samples_per_item = ceil(n_samples_per_basket / b[1])\n",
    "            for i in range(bs, be):\n",
    "                profile = [user.artwork_idxs[j] for j in range(bs, be) if j != i]\n",
    "                assert len(profile) == be - bs - 1\n",
    "                assert len(profile) > 0\n",
    "                \n",
    "                pi = user.artwork_idxs[i]\n",
    "                for _ in range(n_samples_per_item):\n",
    "                    for __ in range(5):\n",
    "                        ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.5)\n",
    "                        if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "3800100 100917\n",
      "collisions =  88974\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_present_hide_rank_one(train_instances, n_samples_per_user=1500)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_present_hide_rank_one(test_instances, n_samples_per_user=20)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('collisions = ', _collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Given the past and the present, hide one and rank it higher than any item of non-purchased artists as long as ResNet50 doesn't disagree by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_present_hide_rank_one(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        if (len(user.baskets) < 2):\n",
    "            continue\n",
    "        u_baskets = user.baskets\n",
    "        u_artwork_idxs = user.artwork_idxs\n",
    "        n_baskets = len(u_baskets)\n",
    "        purchased = []\n",
    "        n_samples_per_basket = ceil(n_samples_per_user / (n_baskets-1))\n",
    "        for i in range(n_baskets):\n",
    "            b = u_baskets[i]\n",
    "            purchased.extend(u_artwork_idxs[j] for j in range(b[0], b[0] + b[1]))\n",
    "            if i == 0:\n",
    "                continue\n",
    "            assert len(purchased) == b[0] + b[1]\n",
    "            jmax = b[0] + (b[1] if b[1] >= 2 else 0)\n",
    "            assert jmax > 0\n",
    "            n_samples_per_item = ceil(n_samples_per_basket / jmax)\n",
    "            for j in range(jmax):\n",
    "                profile = [x for k,x in enumerate(purchased) if k != j]                \n",
    "                pi = u_artwork_idxs[j]\n",
    "                for _ in range(n_samples_per_item):\n",
    "                    for __ in range(5):\n",
    "                        ni = sample_artwork_index__notsharingartist_tripletacceptable(ui, pi, 0.5)\n",
    "                        if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "4540089 143377\n",
      "collisions =  123765\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_past_present_hide_rank_one(train_instances, n_samples_per_user=2100)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_past_present_hide_rank_one(test_instances, n_samples_per_user=20)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('collisions = ', _collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort train and test instances by profile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances.sort(key=lambda x: len(x[0]))\n",
    "test_instances.sort(key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatches(tuples, batch_size):\n",
    "    n_tuples = len(tuples)\n",
    "    n_batches = ceil(n_tuples / batch_size)\n",
    "    \n",
    "    print('n_tuples = ', n_tuples)\n",
    "    print('n_batches = ', n_batches)\n",
    "    \n",
    "    profile_indexes_batches = [None] * n_batches\n",
    "    profile_size_batches = [None] * n_batches\n",
    "    positive_index_batches = [None] * n_batches\n",
    "    negative_index_batches = [None] * n_batches\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        jmin = i * batch_size\n",
    "        jmax = min(jmin + batch_size, n_tuples)\n",
    "        actual_batch_size = jmax - jmin\n",
    "        \n",
    "        profile_maxlen = max(len(tuples[j][0]) for j in range(jmin, jmax))\n",
    "        profile_indexes_batch = np.full((actual_batch_size, profile_maxlen), 0, dtype=int)\n",
    "        profile_size_batch = np.empty((actual_batch_size,))\n",
    "        positive_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        negative_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        \n",
    "        for j in range(actual_batch_size):            \n",
    "            # profile indexes\n",
    "            for k,v in enumerate(tuples[jmin+j][0]):\n",
    "                profile_indexes_batch[j][k] = v\n",
    "            # profile size\n",
    "            profile_size_batch[j] = len(tuples[jmin+j][0])        \n",
    "            # positive index\n",
    "            positive_index_batch[j] = tuples[jmin+j][1]\n",
    "            # negative index\n",
    "            negative_index_batch[j] = tuples[jmin+j][2]\n",
    "            \n",
    "        profile_indexes_batches[i] = profile_indexes_batch\n",
    "        profile_size_batches[i] = profile_size_batch\n",
    "        positive_index_batches[i] = positive_index_batch\n",
    "        negative_index_batches[i] = negative_index_batch\n",
    "        \n",
    "    return dict(\n",
    "        profile_indexes_batches = profile_indexes_batches,\n",
    "        profile_size_batches    = profile_size_batches,\n",
    "        positive_index_batches  = positive_index_batches,\n",
    "        negative_index_batches  = negative_index_batches,\n",
    "        n_batches               = n_batches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_minibatches(minibatches):\n",
    "    profile_indexes_batches = minibatches['profile_indexes_batches']\n",
    "    profile_size_batches = minibatches['profile_size_batches']\n",
    "    positive_index_batches = minibatches['positive_index_batches']\n",
    "    negative_index_batches = minibatches['negative_index_batches']\n",
    "    n_batches = minibatches['n_batches']\n",
    "    assert n_batches == len(profile_indexes_batches)\n",
    "    assert n_batches == len(profile_size_batches)\n",
    "    assert n_batches == len(positive_index_batches)\n",
    "    assert n_batches == len(negative_index_batches)\n",
    "    assert n_batches > 0\n",
    "    \n",
    "    for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "        profile_indexes_batches,\n",
    "        profile_size_batches,\n",
    "        positive_index_batches,\n",
    "        negative_index_batches\n",
    "    ):\n",
    "        n = profile_size.shape[0]\n",
    "        assert n == profile_indexes.shape[0]\n",
    "        assert n == positive_index.shape[0]\n",
    "        assert n == negative_index.shape[0]\n",
    "        \n",
    "        for i in range(n):\n",
    "            assert positive_index[i] != negative_index[i]\n",
    "            psz = int(profile_size[i])\n",
    "            m = profile_indexes[i].shape[0]\n",
    "            assert psz <= m\n",
    "            for j in range(psz, m):\n",
    "                assert profile_indexes[i][j] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/mnt/workspace/pamessina_models/ugallery/youtube_like/v3_hidelast_usermodelbigger/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "from Networks import ContentBasedLearn2RankNetwork, TrainLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(train_minibatches, test_minibatches,\n",
    "                  n_train_instances, n_test_instances, batch_size,\n",
    "                  max_seconds_training=3600,\n",
    "                  min_seconds_to_check_improvement=60,\n",
    "                  early_stopping_checks=4,\n",
    "                  learning_rates=[1e-3]):\n",
    "    \n",
    "    n_train_batches = train_minibatches['n_batches']\n",
    "    n_test_batches = test_minibatches['n_batches']\n",
    "    \n",
    "    print('learning_rates = ', learning_rates)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        network = ContentBasedLearn2RankNetwork(user_model_mode='BIGGER')\n",
    "        with tf.Session() as sess:\n",
    "            try:\n",
    "                saver = tf.train.Saver()            \n",
    "                saver.restore(sess, tf.train.latest_checkpoint(MODEL_PATH))\n",
    "                print('model successfully restored from checkpoint!')\n",
    "            except ValueError:\n",
    "                print('no checkpoint found: initializing variables with random values')\n",
    "                os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "                sess.run(tf.global_variables_initializer())            \n",
    "            trainlogger = TrainLogger(MODEL_PATH + 'train_logs.csv')\n",
    "\n",
    "            # ========= BEFORE TRAINING ============\n",
    "            \n",
    "            initial_test_acc = 0.\n",
    "            for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                test_minibatches['profile_indexes_batches'],\n",
    "                test_minibatches['profile_size_batches'],\n",
    "                test_minibatches['positive_index_batches'],\n",
    "                test_minibatches['negative_index_batches']\n",
    "            ):\n",
    "                minibatch_test_acc = network.get_test_accuracy(\n",
    "                    sess, resnet50_embeddings, profile_indexes, profile_size, positive_index, negative_index)\n",
    "                initial_test_acc += minibatch_test_acc\n",
    "            initial_test_acc /= n_test_instances\n",
    "\n",
    "            print(\"Before training: test_accuracy = %f\" % initial_test_acc)\n",
    "            \n",
    "            best_test_acc = initial_test_acc\n",
    "            seconds_training = 0\n",
    "            elapsed_seconds_from_last_check = 0\n",
    "            checks_with_no_improvement = 0\n",
    "            last_improvement_loss = None\n",
    "            \n",
    "            # ========= TRAINING ============\n",
    "            \n",
    "            print ('Starting training ...')\n",
    "            n_lr = len(learning_rates)\n",
    "            lr_i = 0\n",
    "            train_loss_ema = 0. # exponential moving average\n",
    "            \n",
    "            while seconds_training < max_seconds_training:\n",
    "                \n",
    "                for train_i, (profile_indexes, profile_size, positive_index, negative_index) in enumerate(zip(\n",
    "                    train_minibatches['profile_indexes_batches'],\n",
    "                    train_minibatches['profile_size_batches'],\n",
    "                    train_minibatches['positive_index_batches'],\n",
    "                    train_minibatches['negative_index_batches']\n",
    "                )):\n",
    "                    # optimize and get traing loss\n",
    "                    start_t = time.time()\n",
    "                    _, minibatch_train_loss = network.optimize_and_get_train_loss(\n",
    "                        sess, learning_rates[lr_i], resnet50_embeddings, profile_indexes,\n",
    "                        profile_size, positive_index, negative_index)\n",
    "                    delta_t = time.time() - start_t\n",
    "                    \n",
    "                    # update train loss exponential moving average\n",
    "                    train_loss_ema = 0.999 * train_loss_ema + 0.001 * minibatch_train_loss\n",
    "                    \n",
    "                    # update time tracking variables\n",
    "                    seconds_training += delta_t\n",
    "                    elapsed_seconds_from_last_check += delta_t\n",
    "                    \n",
    "                    # check for improvements using test set if it's time to do so\n",
    "                    if elapsed_seconds_from_last_check >= min_seconds_to_check_improvement:\n",
    "                        \n",
    "                        # --- testing\n",
    "                        test_acc = 0.\n",
    "                        for _profile_indexes, _profile_size, _positive_index, _negative_index in zip(\n",
    "                            test_minibatches['profile_indexes_batches'],\n",
    "                            test_minibatches['profile_size_batches'],\n",
    "                            test_minibatches['positive_index_batches'],\n",
    "                            test_minibatches['negative_index_batches']\n",
    "                        ):\n",
    "                            minibatch_test_acc = network.get_test_accuracy(\n",
    "                                sess, resnet50_embeddings, _profile_indexes,\n",
    "                                _profile_size, _positive_index, _negative_index)                            \n",
    "                            test_acc += minibatch_test_acc\n",
    "                        test_acc /= n_test_instances\n",
    "                    \n",
    "                        print((\"train_i=%d, train_loss = %.12f, test_accuracy = %.5f,\"\n",
    "                               \" check_secs = %.2f, total_secs = %.2f\") % (\n",
    "                                train_i, train_loss_ema, test_acc, elapsed_seconds_from_last_check, seconds_training))                        \n",
    "                        \n",
    "                        # check for improvements\n",
    "                        if (test_acc > best_test_acc) or (\n",
    "                            test_acc == best_test_acc and (\n",
    "                                last_improvement_loss is not None and\\\n",
    "                                last_improvement_loss > train_loss_ema\n",
    "                            )\n",
    "                        ):  \n",
    "                            last_improvement_loss = train_loss_ema\n",
    "                            best_test_acc = test_acc\n",
    "                            checks_with_no_improvement = 0\n",
    "                            saver = tf.train.Saver()\n",
    "                            save_path = saver.save(sess, MODEL_PATH)                    \n",
    "                            print(\"   ** improvement detected: model saved to path \", save_path)\n",
    "                            model_updated = True\n",
    "                        else:\n",
    "                            checks_with_no_improvement += 1                            \n",
    "                            model_updated = False\n",
    "\n",
    "                        # --- logging ---                        \n",
    "                        trainlogger.log_update(\n",
    "                            train_loss_ema, test_acc, n_train_instances, n_test_instances,\n",
    "                            elapsed_seconds_from_last_check, batch_size, learning_rates[lr_i], 't' if model_updated else 'f')\n",
    "                        \n",
    "                        # --- check for early stopping\n",
    "                        if checks_with_no_improvement >= early_stopping_checks:\n",
    "                            if lr_i + 1 < len(learning_rates):\n",
    "                                lr_i += 1\n",
    "                                checks_with_no_improvement = 0\n",
    "                                print(\"   *** %d checks with no improvements -> using a smaller learning_rate = %f\" % (\n",
    "                                    early_stopping_checks, learning_rates[lr_i]))\n",
    "                            else:\n",
    "                                print(\"   *** %d checks with no improvements -> early stopping :(\" % early_stopping_checks)\n",
    "                                return\n",
    "                        \n",
    "                        # --- reset check variables\n",
    "                        elapsed_seconds_from_last_check = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  4540089\n",
      "n_batches =  2217\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 2048\n",
    "train_minibatches = generate_minibatches(train_instances, train_batch_size)\n",
    "sanity_check_minibatches(train_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  143377\n",
      "n_batches =  71\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 2048\n",
    "test_minibatches = generate_minibatches(test_instances, test_batch_size)\n",
    "sanity_check_minibatches(test_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_network(\n",
    "    train_minibatches, test_minibatches,\n",
    "    len(train_instances), len(test_instances), train_batch_size,\n",
    "    max_seconds_training=3600 * 5,\n",
    "    min_seconds_to_check_improvement=150,\n",
    "    early_stopping_checks=7,\n",
    "    learning_rates=[1e-4, 3.33e-5, 1e-5, 3.33e-6, 1e-6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
