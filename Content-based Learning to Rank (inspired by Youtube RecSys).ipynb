{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport utils, Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from os import path\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from math import ceil, floor\n",
    "from utils import load_embeddings_and_ids, User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a single GPU because we want to be nice with other people :)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load pre-trained ResNet50 image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_embeddings,\\\n",
    "artwork_ids,\\\n",
    "artwork_id2index = load_embeddings_and_ids(\n",
    "'/mnt/workspace/Ugallery/ResNet50/', 'flatten_1.npy', 'ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_cluster_labels = np.load('/mnt/workspace/Ugallery/ResNet50/cluster_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13297"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_artworks = len(artwork_ids)\n",
    "n_artworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('./data/valid_sales.csv')\n",
    "artworks_df = pd.read_csv('./data/valid_artworks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_ids = np.full((n_artworks,), -1, dtype=int)\n",
    "for _artworkId, _artistId in zip(artworks_df.id, artworks_df.artist_id):\n",
    "    i = artwork_id2index[_artworkId]\n",
    "    artist_ids[i] = _artistId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistId2artworkIndexes = dict()\n",
    "for i, _artistId in enumerate(artist_ids):\n",
    "    if _artistId == -1:\n",
    "        continue\n",
    "    try:\n",
    "        artistId2artworkIndexes[_artistId].append(i)\n",
    "    except KeyError:\n",
    "        artistId2artworkIndexes[_artistId] = [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect transactions per user (making sure we hide the last nonfirst purchase basket per user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = sales_df.customer_id.unique()\n",
    "user_id2index = { _id:i for i,_id in enumerate(user_ids) }\n",
    "users = [User(uid) for uid in user_ids]\n",
    "n_users = len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect and sanity check transactions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sales_df = sales_df.sort_values('order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear structures to prevent possible duplicate elements\n",
    "for user in users:\n",
    "    user.clear()\n",
    "\n",
    "# collect transactions per user sorted by timestamp\n",
    "for uid, aid, t in zip(sorted_sales_df.customer_id,\n",
    "                       sorted_sales_df.artwork_id,\n",
    "                       sorted_sales_df.order_date):\n",
    "    users[user_id2index[uid]].append_transaction(aid,t,artwork_id2index,artist_ids)\n",
    "    assert users[user_id2index[uid]]._uid == uid\n",
    "    \n",
    "# bin transctions with same timestamps into purchase baskets\n",
    "for user in users:\n",
    "    user.build_purchase_baskets()\n",
    "    user.sanity_check_purchase_baskets()\n",
    "    user.remove_last_nonfirst_purchase_basket(artwork_id2index, artist_ids)\n",
    "    user.sanity_check_purchase_baskets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute minimun cosine distance from each user profile to each item in the dataset\n",
    "\\* using R200 vectors obtained with PCA(200) over ResNet50 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_PCA200 = PCA(n_components=200).fit_transform(resnet50_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 200)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_PCA200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat = squareform(pdist(resnet50_PCA200, 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user2artwork_mindist():\n",
    "    user2artwork_mindist = np.empty((n_users, n_artworks), dtype=object)\n",
    "    for ui in tqdm(range(n_users)):\n",
    "        user = users[ui]\n",
    "        baskets = user.baskets\n",
    "        artwork_idxs = user.artwork_idxs\n",
    "        nb = len(baskets)\n",
    "        for ai in range(n_artworks):\n",
    "            mindist = user2artwork_mindist[ui][ai] = np.empty((nb,))\n",
    "            tmp = 99999999\n",
    "            start = 0\n",
    "            for bi, b in enumerate(baskets):\n",
    "                end = b[0] + b[1]\n",
    "                tmp = mindist[bi] = min(tmp, min(distmat[ai][artwork_idxs[j]] for j in range(start, end)))\n",
    "                start = end\n",
    "    return user2artwork_mindist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [01:27<00:00, 33.37it/s]\n"
     ]
    }
   ],
   "source": [
    "user2artwork_mindist = get_user2artwork_mindist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash(profile, pi, ni):\n",
    "    h = 0\n",
    "    for x in profile:\n",
    "        h = (h * 127) % 1000000007 + x\n",
    "    h = (h * 127) % 1000000007 + pi\n",
    "    h = (h * 127) % 1000000007 + ni\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_instance(instance, pos_is_purchased=True, not_sharing_artist=True):\n",
    "    profile, pi, ni, ui = instance\n",
    "    try:\n",
    "        assert 0 <= pi < n_artworks\n",
    "        assert 0 <= ni < n_artworks\n",
    "        assert pi != ni\n",
    "        assert distmat[pi][ni] > 0\n",
    "        if ui == -1: return\n",
    "        \n",
    "        assert 0 <= ui < n_users\n",
    "        user = users[ui]\n",
    "        assert all(i in user.artwork_idxs_set for i in profile)\n",
    "        if pos_is_purchased is not None:\n",
    "            if pos_is_purchased:\n",
    "                assert pi in user.artwork_idxs_set\n",
    "            else:\n",
    "                assert pi not in user.artwork_idxs_set\n",
    "        assert ni not in user.artwork_idxs_set        \n",
    "        if not_sharing_artist:\n",
    "            assert artist_ids[ni] not in user.artist_ids_set\n",
    "    except AssertionError:\n",
    "        print('profile = ', profile)\n",
    "        print('pi = ', pi)\n",
    "        print('ni = ', ni)\n",
    "        print('ui = ', ui)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_instance(container, instance, **kwargs):\n",
    "    global _hash_collisions, _visual_collisions\n",
    "    h = hash(instance[0], instance[1], instance[2])\n",
    "    if h in used_hashes:\n",
    "        _hash_collisions += 1\n",
    "        return False\n",
    "    pi, ni, ui = instance[1], instance[2], instance[3]\n",
    "    if distmat[pi][ni] == 0 or (ui != -1 and user2artwork_mindist[ui][ni][-1] == 0):\n",
    "        _visual_collisions += 1\n",
    "        return False\n",
    "    sanity_check_instance(instance, **kwargs)\n",
    "    container.append(instance)\n",
    "    used_hashes.add(h)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_hashes = set()\n",
    "_hash_collisions = 0\n",
    "_visual_collisions = 0\n",
    "train_instances = []\n",
    "test_instances = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0) Given a profile of a single item, such item should be ranked higher than any other item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonidentical(i):\n",
    "    while True:\n",
    "        j = random.randint(0, n_artworks-1)\n",
    "        if distmat[i][j] > 0:\n",
    "            return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_single_item_above_anything_else(instances_container, n_samples_per_item):\n",
    "    for pi in range(n_artworks):\n",
    "        profile = (pi,)\n",
    "        n = n_samples_per_item\n",
    "        while n > 0:\n",
    "            ni = sample_artwork_index__nonidentical(pi)\n",
    "            if append_instance(instances_container, (profile, pi, ni, -1)):\n",
    "                n -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "1595640 53188\n",
      "hash_collisions =  7658\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_single_item_above_anything_else(train_instances, n_samples_per_item=120)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_single_item_above_anything_else(test_instances, n_samples_per_item=4)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Given a profile of a single item, other items sharing the same artist should be ranked higher than items of different artists as long as ResNet50 agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonidentical_sharingartist(i):\n",
    "    aid = artist_ids[i]\n",
    "    assert aid != -1\n",
    "    candidate_idxs = artistId2artworkIndexes[aid]\n",
    "    assert len(candidate_idxs) >= 2\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        j = random.choice(candidate_idxs)\n",
    "        if distmat[i][j] > 0: return j\n",
    "    return None # failed to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist_visuallyacceptable(i, pi):    \n",
    "    aid = artist_ids[i]\n",
    "    assert aid != -1\n",
    "    assert artist_ids[pi]  == aid\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        ni = random.randint(0, n_artworks-1)\n",
    "        if artist_ids[ni] != aid and distmat[i][pi] < distmat[i][ni]:\n",
    "            return ni\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_i = 1500\n",
    "# print(artist_ids[debug_i])\n",
    "# debug_pi = sample_artwork_index__nonidentical_sharingartist(debug_i)\n",
    "# debug_ni = sample_artwork_index__notsharingartist_visuallyacceptable(debug_i, debug_pi)\n",
    "# artwork_ids[debug_i], artwork_ids[debug_pi], artwork_ids[debug_ni]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_single_item_artist_above_other_artists(instances_container, n_samples_per_item):\n",
    "    for i in range(n_artworks):\n",
    "        aid = artist_ids[i]\n",
    "        if aid == -1 or len(artistId2artworkIndexes[aid]) < 2:\n",
    "            continue\n",
    "        profile = (i,)\n",
    "        for _ in range(n_samples_per_item):\n",
    "            for __ in range(5):\n",
    "                pi = sample_artwork_index__nonidentical_sharingartist(i)\n",
    "                if pi is None: continue                \n",
    "                ni = sample_artwork_index__notsharingartist_visuallyacceptable(i, pi)\n",
    "                if ni is None: continue\n",
    "                if append_instance(instances_container, (profile, pi, ni, -1)):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "2354255 83532\n",
      "hash_collisions =  15379\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_single_item_artist_above_other_artists(train_instances, n_samples_per_item=100)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_single_item_artist_above_other_artists(test_instances, n_samples_per_item=4)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Given a list of purchased items, each purchased item should trivially be ranked higher than any non-purchased item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonpurchased(purchased_artwork_idxs):\n",
    "    while True:\n",
    "        i = random.randint(0, n_artworks-1)\n",
    "        if i not in purchased_artwork_idxs:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_above_nonpurchased(instances_container, n_samples_per_user):    \n",
    "    for ui, user in enumerate(users):\n",
    "        profile = user.artwork_idxs\n",
    "        profile_set = user.artwork_idxs_set\n",
    "        for _ in range(n_samples_per_user):\n",
    "            for __ in range(5):\n",
    "                pi = random.choice(profile)\n",
    "                ni = sample_artwork_index__nonpurchased(profile_set)\n",
    "                if append_instance(instances_container, (profile, pi, ni, ui), not_sharing_artist=False):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "4105642 112722\n",
      "hash_collisions =  77559\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_purchased_above_nonpurchased(train_instances, n_samples_per_user=600)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_purchased_above_nonpurchased(test_instances, n_samples_per_user=10)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Given a user, any non-purchased item sharing the same artist with a purchased item should be ranked higher than any item of a non-purchased artist as long as ResNet50 agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonpurchased_sharingartist(artist_id, artwork_idxs_set):\n",
    "    candidate_idxs = artistId2artworkIndexes[artist_id]\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        i = random.choice(candidate_idxs)\n",
    "        if i not in artwork_idxs_set:\n",
    "            return i\n",
    "    return None # failed to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist_visuallyacceptable_largeprofile(ui, pi, bi):\n",
    "    artist_ids_set = users[ui].artist_ids_set\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        ni = random.randint(0, n_artworks-1)\n",
    "        if artist_ids[ni] not in artist_ids_set and (\n",
    "            user2artwork_mindist[ui][pi][bi] < user2artwork_mindist[ui][ni][bi]):\n",
    "            return ni\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_artist_above_nonpurchased_artist(instances_container, n_samples_per_user=500):\n",
    "    for ui, user in enumerate(users):\n",
    "        profile = user.artwork_idxs\n",
    "        profile_set = user.artwork_idxs_set\n",
    "        for _ in range(n_samples_per_user):\n",
    "            for __ in range(5):\n",
    "                aid = artist_ids[random.choice(profile)]\n",
    "                assert aid != -1\n",
    "                pi = sample_artwork_index__nonpurchased_sharingartist(aid, profile_set)\n",
    "                if pi is None: continue\n",
    "                ni = sample_artwork_index__notsharingartist_visuallyacceptable_largeprofile(ui, pi, -1)\n",
    "                if ni is None: continue\n",
    "                if append_instance(instances_container, (profile, pi, ni, ui), pos_is_purchased=False):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "5251723 141375\n",
      "hash_collisions =  101010\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_purchased_artist_above_nonpurchased_artist(train_instances, n_samples_per_user=400)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_purchased_artist_above_nonpurchased_artist(test_instances, n_samples_per_user=10)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Given all previous purchases, rank each  item of the next purchase basket higher than any item of non-purchased artists as long as resnet50 agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_rank_next(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        n = len(user.baskets)\n",
    "        if n <= 1:\n",
    "            continue\n",
    "        past_items = []\n",
    "        n_samples_per_basket = ceil(n_samples_per_user / (n-1))\n",
    "        for bi in range(n-1):\n",
    "            cur_b = user.baskets[bi]\n",
    "            for j in range(cur_b[0], cur_b[0] + cur_b[1]):\n",
    "                past_items.append(user.artwork_idxs[j])\n",
    "            next_b  = user.baskets[bi+1]\n",
    "            profile = past_items.copy()\n",
    "            for _ in range(n_samples_per_basket):\n",
    "                for __ in range(5):\n",
    "                    pi = user.artwork_idxs[random.randint(next_b[0], next_b[0] + next_b[1] - 1)]\n",
    "                    ni = sample_artwork_index__notsharingartist_visuallyacceptable_largeprofile(ui, pi, bi)\n",
    "                    if ni is None: continue\n",
    "                    if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "6238045 189533\n",
      "hash_collisions =  332233\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_past_rank_next(train_instances, n_samples_per_user=3000)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_past_rank_next(test_instances, n_samples_per_user=150)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Given only the present purchase basket, hide one and rank it higher than any item of non-purchased artists and not-sharing visual cluster ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist_notsharingcluster(ui, pi, clusters):\n",
    "    artist_ids_set = users[ui].artist_ids_set\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        ni = random.randint(0, n_artworks-1)\n",
    "        if artist_ids[ni] not in artist_ids_set and resnet50_cluster_labels[ni] not in clusters:\n",
    "            return ni\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_present_hide_rank_one(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        n = sum(1 if b[1] >=2 else 0 for b in user.baskets)\n",
    "        if n == 0:\n",
    "            continue\n",
    "        n_samples_per_basket = ceil(n_samples_per_user / n)\n",
    "        for b in user.baskets:\n",
    "            if b[1] < 2:\n",
    "                continue\n",
    "            bs = b[0]\n",
    "            be = b[0] + b[1]\n",
    "            n_samples_per_item = ceil(n_samples_per_basket / b[1])\n",
    "            \n",
    "            for i in range(bs, be):\n",
    "                profile = [user.artwork_idxs[j] for j in range(bs, be) if j != i]\n",
    "                profile_clusters = set(resnet50_cluster_labels[j] for j in profile)\n",
    "                assert len(profile) == be - bs - 1\n",
    "                assert len(profile) > 0\n",
    "                assert len(profile_clusters) < 100\n",
    "                pi = user.artwork_idxs[i]\n",
    "                for _ in range(n_samples_per_item):\n",
    "                    for __ in range(5):\n",
    "                        ni = sample_artwork_index__notsharingartist_notsharingcluster(ui, pi, profile_clusters)\n",
    "                        if ni is None: continue\n",
    "                        if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "7116664 208424\n",
      "hash_collisions =  373351\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_present_hide_rank_one(train_instances, n_samples_per_user=1500)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_present_hide_rank_one(test_instances, n_samples_per_user=30)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Given the past and the present, hide one and rank it higher than any item of non-purchased artists and not sharing visual cluster ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_present_hide_rank_one(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        if (len(user.baskets) < 2):\n",
    "            continue\n",
    "        u_baskets = user.baskets\n",
    "        u_artwork_idxs = user.artwork_idxs\n",
    "        n_baskets = len(u_baskets)\n",
    "        purchased = []\n",
    "        n_samples_per_basket = ceil(n_samples_per_user / (n_baskets-1))\n",
    "        for i in range(n_baskets):\n",
    "            b = u_baskets[i]\n",
    "            purchased.extend(u_artwork_idxs[j] for j in range(b[0], b[0] + b[1]))\n",
    "            if i == 0:\n",
    "                continue\n",
    "            assert len(purchased) == b[0] + b[1]\n",
    "            jmax = b[0] + (b[1] if b[1] >= 2 else 0)\n",
    "            assert jmax > 0\n",
    "            n_samples_per_item = ceil(n_samples_per_basket / jmax)\n",
    "            for j in range(jmax):\n",
    "                profile = [x for k,x in enumerate(purchased) if k != j]\n",
    "                profile_clusters = set(resnet50_cluster_labels[j] for j in profile)\n",
    "                assert len(profile_clusters) < 100\n",
    "                pi = u_artwork_idxs[j]\n",
    "                for _ in range(n_samples_per_item):\n",
    "                    for __ in range(5):\n",
    "                        ni = sample_artwork_index__notsharingartist_notsharingcluster(ui, pi, profile_clusters)\n",
    "                        if ni is None: continue\n",
    "                        if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "7654355 250884\n",
      "hash_collisions =  397169\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_past_present_hide_rank_one(train_instances, n_samples_per_user=1500)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_past_present_hide_rank_one(test_instances, n_samples_per_user=20)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort train and test instances by profile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances.sort(key=lambda x: len(x[0]))\n",
    "test_instances.sort(key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatches(tuples, batch_size):\n",
    "    n_tuples = len(tuples)\n",
    "    n_batches = ceil(n_tuples / batch_size)\n",
    "    \n",
    "    print('n_tuples = ', n_tuples)\n",
    "    print('n_batches = ', n_batches)\n",
    "    \n",
    "    profile_indexes_batches = [None] * n_batches\n",
    "    profile_size_batches = [None] * n_batches\n",
    "    positive_index_batches = [None] * n_batches\n",
    "    negative_index_batches = [None] * n_batches\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        jmin = i * batch_size\n",
    "        jmax = min(jmin + batch_size, n_tuples)\n",
    "        actual_batch_size = jmax - jmin\n",
    "        \n",
    "        profile_maxlen = max(len(tuples[j][0]) for j in range(jmin, jmax))\n",
    "        profile_indexes_batch = np.full((actual_batch_size, profile_maxlen), 0, dtype=int)\n",
    "        profile_size_batch = np.empty((actual_batch_size,))\n",
    "        positive_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        negative_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        \n",
    "        for j in range(actual_batch_size):            \n",
    "            # profile indexes\n",
    "            for k,v in enumerate(tuples[jmin+j][0]):\n",
    "                profile_indexes_batch[j][k] = v\n",
    "            # profile size\n",
    "            profile_size_batch[j] = len(tuples[jmin+j][0])        \n",
    "            # positive index\n",
    "            positive_index_batch[j] = tuples[jmin+j][1]\n",
    "            # negative index\n",
    "            negative_index_batch[j] = tuples[jmin+j][2]\n",
    "            \n",
    "        profile_indexes_batches[i] = profile_indexes_batch\n",
    "        profile_size_batches[i] = profile_size_batch\n",
    "        positive_index_batches[i] = positive_index_batch\n",
    "        negative_index_batches[i] = negative_index_batch\n",
    "        \n",
    "    return dict(\n",
    "        profile_indexes_batches = profile_indexes_batches,\n",
    "        profile_size_batches    = profile_size_batches,\n",
    "        positive_index_batches  = positive_index_batches,\n",
    "        negative_index_batches  = negative_index_batches,\n",
    "        n_batches               = n_batches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_minibatches(minibatches):\n",
    "    profile_indexes_batches = minibatches['profile_indexes_batches']\n",
    "    profile_size_batches = minibatches['profile_size_batches']\n",
    "    positive_index_batches = minibatches['positive_index_batches']\n",
    "    negative_index_batches = minibatches['negative_index_batches']\n",
    "    n_batches = minibatches['n_batches']\n",
    "    assert n_batches == len(profile_indexes_batches)\n",
    "    assert n_batches == len(profile_size_batches)\n",
    "    assert n_batches == len(positive_index_batches)\n",
    "    assert n_batches == len(negative_index_batches)\n",
    "    assert n_batches > 0\n",
    "    \n",
    "    for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "        profile_indexes_batches,\n",
    "        profile_size_batches,\n",
    "        positive_index_batches,\n",
    "        negative_index_batches\n",
    "    ):\n",
    "        n = profile_size.shape[0]\n",
    "        assert n == profile_indexes.shape[0]\n",
    "        assert n == positive_index.shape[0]\n",
    "        assert n == negative_index.shape[0]\n",
    "        \n",
    "        for i in range(n):\n",
    "            assert positive_index[i] != negative_index[i]\n",
    "            psz = int(profile_size[i])\n",
    "            m = profile_indexes[i].shape[0]\n",
    "            assert psz <= m\n",
    "            for j in range(psz, m):\n",
    "                assert profile_indexes[i][j] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/mnt/workspace/pamessina_models/ugallery/youtube_like/v8_avgpool+maxpool_prednextbasket_hideandpred/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Networks import ContentBasedLearn2RankNetwork_Train, TrainLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # DEBUGGING NETWORK\n",
    "# with tf.Graph().as_default():\n",
    "#     network = ContentBasedLearn2RankNetwork_Train(profile_pooling_mode='AVG+MAX')\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         debug_ = sess.run(\n",
    "#             [network._profile_masks__avgpool,\n",
    "#              network._profile_masks__maxpool,\n",
    "#              network._masked_profile_item_embeddings__avgpool,\n",
    "#              network._masked_profile_item_embeddings__maxpool,\n",
    "#              network._profile_items_avgpool,\n",
    "#              network._profile_items_maxpool,\n",
    "#             ], feed_dict={\n",
    "#                 network._pretrained_embeddings: resnet50_embeddings,\n",
    "#                 network._profile_item_indexes: [[0,1,2,9,9,9], [1,2,3,4,5,6]],\n",
    "#                 network._profile_sizes: [3,6],\n",
    "#             }\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(train_minibatches, test_minibatches,\n",
    "                  n_train_instances, n_test_instances, batch_size,\n",
    "                  max_seconds_training=3600,\n",
    "                  min_seconds_to_check_improvement=60,\n",
    "                  early_stopping_checks=4,\n",
    "                  learning_rates=[1e-3]):\n",
    "    \n",
    "    n_train_batches = train_minibatches['n_batches']\n",
    "    n_test_batches = test_minibatches['n_batches']\n",
    "    \n",
    "    print('learning_rates = ', learning_rates)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        network = ContentBasedLearn2RankNetwork_Train(profile_pooling_mode='AVG+MAX')\n",
    "        with tf.Session() as sess:\n",
    "            try:\n",
    "                saver = tf.train.Saver()            \n",
    "                saver.restore(sess, tf.train.latest_checkpoint(MODEL_PATH))\n",
    "                print('model successfully restored from checkpoint!')\n",
    "            except ValueError:\n",
    "                print('no checkpoint found: initializing variables with random values')\n",
    "                os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "                sess.run(tf.global_variables_initializer())            \n",
    "            trainlogger = TrainLogger(MODEL_PATH + 'train_logs.csv')\n",
    "\n",
    "            # ========= BEFORE TRAINING ============\n",
    "            \n",
    "            initial_test_acc = 0.\n",
    "            for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                test_minibatches['profile_indexes_batches'],\n",
    "                test_minibatches['profile_size_batches'],\n",
    "                test_minibatches['positive_index_batches'],\n",
    "                test_minibatches['negative_index_batches']\n",
    "            ):\n",
    "                minibatch_test_acc = network.get_test_accuracy(\n",
    "                    sess, resnet50_embeddings, profile_indexes, profile_size, positive_index, negative_index)\n",
    "                initial_test_acc += minibatch_test_acc\n",
    "            initial_test_acc /= n_test_instances\n",
    "\n",
    "            print(\"Before training: test_accuracy = %f\" % initial_test_acc)\n",
    "            \n",
    "            best_test_acc = initial_test_acc\n",
    "            seconds_training = 0\n",
    "            elapsed_seconds_from_last_check = 0\n",
    "            checks_with_no_improvement = 0\n",
    "            last_improvement_loss = None\n",
    "            \n",
    "            # ========= TRAINING ============\n",
    "            \n",
    "            print ('Starting training ...')\n",
    "            n_lr = len(learning_rates)\n",
    "            lr_i = 0\n",
    "            train_loss_ema = 0. # exponential moving average\n",
    "            \n",
    "            while seconds_training < max_seconds_training:\n",
    "                \n",
    "                for train_i, (profile_indexes, profile_size, positive_index, negative_index) in enumerate(zip(\n",
    "                    train_minibatches['profile_indexes_batches'],\n",
    "                    train_minibatches['profile_size_batches'],\n",
    "                    train_minibatches['positive_index_batches'],\n",
    "                    train_minibatches['negative_index_batches']\n",
    "                )):\n",
    "                    # optimize and get traing loss\n",
    "                    start_t = time.time()\n",
    "                    _, minibatch_train_loss = network.optimize_and_get_train_loss(\n",
    "                        sess, learning_rates[lr_i], resnet50_embeddings, profile_indexes,\n",
    "                        profile_size, positive_index, negative_index)\n",
    "                    delta_t = time.time() - start_t\n",
    "                    \n",
    "                    # update train loss exponential moving average\n",
    "                    train_loss_ema = 0.999 * train_loss_ema + 0.001 * minibatch_train_loss\n",
    "                    \n",
    "                    # update time tracking variables\n",
    "                    seconds_training += delta_t\n",
    "                    elapsed_seconds_from_last_check += delta_t\n",
    "                    \n",
    "                    # check for improvements using test set if it's time to do so\n",
    "                    if elapsed_seconds_from_last_check >= min_seconds_to_check_improvement:\n",
    "                        \n",
    "                        # --- testing\n",
    "                        test_acc = 0.\n",
    "                        for _profile_indexes, _profile_size, _positive_index, _negative_index in zip(\n",
    "                            test_minibatches['profile_indexes_batches'],\n",
    "                            test_minibatches['profile_size_batches'],\n",
    "                            test_minibatches['positive_index_batches'],\n",
    "                            test_minibatches['negative_index_batches']\n",
    "                        ):\n",
    "                            minibatch_test_acc = network.get_test_accuracy(\n",
    "                                sess, resnet50_embeddings, _profile_indexes,\n",
    "                                _profile_size, _positive_index, _negative_index)                            \n",
    "                            test_acc += minibatch_test_acc\n",
    "                        test_acc /= n_test_instances\n",
    "                    \n",
    "                        print((\"train_i=%d, train_loss = %.12f, test_accuracy = %.5f,\"\n",
    "                               \" check_secs = %.2f, total_secs = %.2f\") % (\n",
    "                                train_i, train_loss_ema, test_acc, elapsed_seconds_from_last_check, seconds_training))                        \n",
    "                        \n",
    "                        # check for improvements\n",
    "                        if (test_acc > best_test_acc) or (\n",
    "                            test_acc == best_test_acc and (\n",
    "                                last_improvement_loss is not None and\\\n",
    "                                last_improvement_loss > train_loss_ema\n",
    "                            )\n",
    "                        ):  \n",
    "                            last_improvement_loss = train_loss_ema\n",
    "                            best_test_acc = test_acc\n",
    "                            checks_with_no_improvement = 0\n",
    "                            saver = tf.train.Saver()\n",
    "                            save_path = saver.save(sess, MODEL_PATH)                    \n",
    "                            print(\"   ** improvement detected: model saved to path \", save_path)\n",
    "                            model_updated = True\n",
    "                        else:\n",
    "                            checks_with_no_improvement += 1                            \n",
    "                            model_updated = False\n",
    "\n",
    "                        # --- logging ---                        \n",
    "                        trainlogger.log_update(\n",
    "                            train_loss_ema, test_acc, n_train_instances, n_test_instances,\n",
    "                            elapsed_seconds_from_last_check, batch_size, learning_rates[lr_i], 't' if model_updated else 'f')\n",
    "                        \n",
    "                        # --- check for early stopping\n",
    "                        if checks_with_no_improvement >= early_stopping_checks:\n",
    "                            if lr_i + 1 < len(learning_rates):\n",
    "                                lr_i += 1\n",
    "                                checks_with_no_improvement = 0\n",
    "                                print(\"   *** %d checks with no improvements -> using a smaller learning_rate = %f\" % (\n",
    "                                    early_stopping_checks, learning_rates[lr_i]))\n",
    "                            else:\n",
    "                                print(\"   *** %d checks with no improvements -> early stopping :(\" % early_stopping_checks)\n",
    "                                return\n",
    "                        \n",
    "                        # --- reset check variables\n",
    "                        elapsed_seconds_from_last_check = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  7654355\n",
      "n_batches =  3738\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 2048\n",
    "train_minibatches = generate_minibatches(train_instances, train_batch_size)\n",
    "sanity_check_minibatches(train_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  250884\n",
      "n_batches =  123\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 2048\n",
    "test_minibatches = generate_minibatches(test_instances, test_batch_size)\n",
    "sanity_check_minibatches(test_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rates =  [3.33e-06, 1e-06]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/pamessina_models/ugallery/youtube_like/v8_avgpool+maxpool_prednextbasket_hideandpred/\n",
      "model successfully restored from checkpoint!\n",
      "Before training: test_accuracy = 0.999705\n",
      "Starting training ...\n",
      "train_i=725, train_loss = 0.000000365864, test_accuracy = 0.99969, check_secs = 200.00, total_secs = 200.00\n",
      "train_i=1598, train_loss = 0.000000164150, test_accuracy = 0.99972, check_secs = 200.03, total_secs = 400.03\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v8_avgpool+maxpool_prednextbasket_hideandpred/\n",
      "train_i=2476, train_loss = 0.000000070654, test_accuracy = 0.99970, check_secs = 200.00, total_secs = 600.04\n",
      "train_i=3344, train_loss = 0.000000029984, test_accuracy = 0.99972, check_secs = 200.02, total_secs = 800.05\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v8_avgpool+maxpool_prednextbasket_hideandpred/\n",
      "train_i=344, train_loss = 0.000000233125, test_accuracy = 0.99971, check_secs = 200.01, total_secs = 1000.07\n"
     ]
    }
   ],
   "source": [
    "train_network(\n",
    "    train_minibatches, test_minibatches,\n",
    "    len(train_instances), len(test_instances), train_batch_size,\n",
    "    max_seconds_training=3600 * 0.3,\n",
    "    min_seconds_to_check_improvement=200,\n",
    "    early_stopping_checks=3,\n",
    "#     learning_rates=[1e-4, 3.33e-5, 1e-5, 3.33e-6, 1e-6])\n",
    "    learning_rates=[3.33e-6, 1e-6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
