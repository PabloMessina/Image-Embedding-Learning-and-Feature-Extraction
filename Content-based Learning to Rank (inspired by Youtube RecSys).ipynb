{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport utils, Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from os import path\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from math import ceil, floor\n",
    "from utils import load_embeddings_and_ids, User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a single GPU because we want to be nice with other people :)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load pre-trained ResNet50 image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_embeddings,\\\n",
    "artwork_ids,\\\n",
    "artwork_id2index = load_embeddings_and_ids(\n",
    "'/mnt/workspace/Ugallery/ResNet50/', 'flatten_1.npy', 'ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13297"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_artworks = len(artwork_ids)\n",
    "n_artworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('./valid_sales.csv')\n",
    "artworks_df = pd.read_csv('./valid_artworks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_ids = np.full((n_artworks,), -1, dtype=int)\n",
    "for _artworkId, _artistId in zip(artworks_df.id, artworks_df.artist_id):\n",
    "    i = artwork_id2index[_artworkId]\n",
    "    artist_ids[i] = _artistId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistId2artworkIndexes = dict()\n",
    "for i, _artistId in enumerate(artist_ids):\n",
    "    if _artistId == -1:\n",
    "        continue\n",
    "    try:\n",
    "        artistId2artworkIndexes[_artistId].append(i)\n",
    "    except KeyError:\n",
    "        artistId2artworkIndexes[_artistId] = [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect transactions per user (making sure we hide the last nonfirst purchase basket per user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = sales_df.customer_id.unique()\n",
    "user_id2index = { _id:i for i,_id in enumerate(user_ids) }\n",
    "users = [User(uid) for uid in user_ids]\n",
    "n_users = len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect and sanity check transactions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sales_df = sales_df.sort_values('order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear structures to prevent possible duplicate elements\n",
    "for user in users:\n",
    "    user.clear()\n",
    "\n",
    "# collect transactions per user sorted by timestamp\n",
    "for uid, aid, t in zip(sorted_sales_df.customer_id,\n",
    "                       sorted_sales_df.artwork_id,\n",
    "                       sorted_sales_df.order_date):\n",
    "    users[user_id2index[uid]].append_transaction(aid,t,artwork_id2index,artist_ids)\n",
    "    assert users[user_id2index[uid]]._uid == uid\n",
    "    \n",
    "# bin transctions with same timestamps into purchase baskets\n",
    "for user in users:\n",
    "    user.build_purchase_baskets()\n",
    "    user.sanity_check_purchase_baskets()\n",
    "#     user.remove_last_nonfirst_purchase_basket(artwork_id2index, artist_ids)\n",
    "#     user.sanity_check_purchase_baskets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute minimun cosine distance from each user profile to each item in the dataset\n",
    "\\* using R200 vectors obtained with PCA(200) over ResNet50 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_PCA200 = PCA(n_components=200).fit_transform(resnet50_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_PCA200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat = squareform(pdist(resnet50_PCA200, 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2artwork_mindist = np.empty((n_users, n_artworks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [00:45<00:00, 64.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for ui in tqdm(range(n_users)):\n",
    "    for ai in range(n_artworks):\n",
    "        user2artwork_mindist[ui][ai] = min(distmat[ai][j] for j in users[ui].artwork_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash(profile, pi, ni):\n",
    "    h = 0\n",
    "    for x in profile:\n",
    "        h = (h * 127) % 1000000007 + x\n",
    "    h = (h * 127) % 1000000007 + pi\n",
    "    h = (h * 127) % 1000000007 + ni\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_instance(instance, pos_is_purchased=True, not_sharing_artist=True):\n",
    "    profile, pi, ni, ui = instance\n",
    "    try:\n",
    "        assert 0 <= pi < n_artworks\n",
    "        assert 0 <= ni < n_artworks\n",
    "        assert pi != ni\n",
    "        assert distmat[pi][ni] > 0\n",
    "        if ui == -1: return\n",
    "        \n",
    "        assert 0 <= ui < n_users\n",
    "        user = users[ui]\n",
    "        assert all(i in user.artwork_idxs_set for i in profile)\n",
    "        if pos_is_purchased is not None:\n",
    "            if pos_is_purchased:\n",
    "                assert pi in user.artwork_idxs_set\n",
    "            else:\n",
    "                assert pi not in user.artwork_idxs_set\n",
    "        assert ni not in user.artwork_idxs_set        \n",
    "        if not_sharing_artist:\n",
    "            assert artist_ids[ni] not in user.artist_ids_set\n",
    "    except AssertionError:\n",
    "        print('profile = ', profile)\n",
    "        print('pi = ', pi)\n",
    "        print('ni = ', ni)\n",
    "        print('ui = ', ui)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_instance(container, instance, **kwargs):\n",
    "    global _hash_collisions, _visual_collisions\n",
    "    h = hash(instance[0], instance[1], instance[2])\n",
    "    if h in used_hashes:\n",
    "        _hash_collisions += 1\n",
    "        return False\n",
    "    pi, ni, ui = instance[1], instance[2], instance[3]\n",
    "    if distmat[pi][ni] == 0 or (ui != -1 and user2artwork_mindist[ui][ni] == 0):\n",
    "        _visual_collisions += 1\n",
    "        return False\n",
    "    sanity_check_instance(instance, **kwargs)\n",
    "    container.append(instance)\n",
    "    used_hashes.add(h)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_hashes = set()\n",
    "_hash_collisions = 0\n",
    "_visual_collisions = 0\n",
    "train_instances = []\n",
    "test_instances = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0) Given a profile of a single item, such item should be ranked higher than any other item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonidentical(i):\n",
    "    while True:\n",
    "        j = random.randint(0, n_artworks-1)\n",
    "        if distmat[i][j] > 0:\n",
    "            return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_single_item_above_anything_else(instances_container, n_samples_per_item):\n",
    "    for pi in range(n_artworks):\n",
    "        profile = (pi,)\n",
    "        n = n_samples_per_item\n",
    "        while n > 0:\n",
    "            ni = sample_artwork_index__nonidentical(pi)\n",
    "            if append_instance(instances_container, (profile, pi, ni, -1)):\n",
    "                n -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "1329700 53188\n",
      "hash_collisions =  5394\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_single_item_above_anything_else(train_instances, n_samples_per_item=100)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_single_item_above_anything_else(test_instances, n_samples_per_item=4)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Given a profile of a single item, other items sharing the same artist should be ranked higher than items of different artists as long as ResNet50 agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonidentical_sharingartist(i):\n",
    "    aid = artist_ids[i]\n",
    "    assert aid != -1\n",
    "    candidate_idxs = artistId2artworkIndexes[aid]\n",
    "    assert len(candidate_idxs) >= 2\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        j = random.choice(candidate_idxs)\n",
    "        if distmat[i][j] > 0: return j\n",
    "    return None # failed to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist_visuallyacceptable(i, pi):    \n",
    "    aid = artist_ids[i]\n",
    "    assert aid != -1\n",
    "    assert artist_ids[pi]  == aid\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        ni = random.randint(0, n_artworks-1)\n",
    "        if artist_ids[ni] != aid and distmat[i][pi] < distmat[i][ni]:\n",
    "            return ni\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_i = 1500\n",
    "# print(artist_ids[debug_i])\n",
    "# debug_pi = sample_artwork_index__nonidentical_sharingartist(debug_i)\n",
    "# debug_ni = sample_artwork_index__notsharingartist_visuallyacceptable(debug_i, debug_pi)\n",
    "# artwork_ids[debug_i], artwork_ids[debug_pi], artwork_ids[debug_ni]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_single_item_artist_above_other_artists(instances_container, n_samples_per_item):\n",
    "    for i in range(n_artworks):\n",
    "        aid = artist_ids[i]\n",
    "        if aid == -1 or len(artistId2artworkIndexes[aid]) < 2:\n",
    "            continue\n",
    "        profile = (i,)\n",
    "        for _ in range(n_samples_per_item):\n",
    "            for __ in range(5):\n",
    "                pi = sample_artwork_index__nonidentical_sharingartist(i)\n",
    "                if pi is None: continue                \n",
    "                ni = sample_artwork_index__notsharingartist_visuallyacceptable(i, pi)\n",
    "                if ni is None: continue\n",
    "                if append_instance(instances_container, (profile, pi, ni, -1)):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "2088328 83534\n",
      "hash_collisions =  12306\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_single_item_artist_above_other_artists(train_instances, n_samples_per_item=100)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_single_item_artist_above_other_artists(test_instances, n_samples_per_item=4)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Given a list of purchased items, each purchased item should trivially be ranked higher than any non-purchased item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonpurchased(purchased_artwork_idxs):\n",
    "    while True:\n",
    "        i = random.randint(0, n_artworks-1)\n",
    "        if i not in purchased_artwork_idxs:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_above_nonpurchased(instances_container, n_samples_per_user):    \n",
    "    for ui, user in enumerate(users):\n",
    "        profile = user.artwork_idxs\n",
    "        profile_set = user.artwork_idxs_set\n",
    "        for _ in range(n_samples_per_user):\n",
    "            for __ in range(5):\n",
    "                pi = random.choice(profile)\n",
    "                ni = sample_artwork_index__nonpurchased(profile_set)\n",
    "                if append_instance(instances_container, (profile, pi, ni, ui), not_sharing_artist=False):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "3839717 112721\n",
      "hash_collisions =  66610\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_purchased_above_nonpurchased(train_instances, n_samples_per_user=600)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_purchased_above_nonpurchased(test_instances, n_samples_per_user=10)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Given a user, any non-purchased item sharing the same artist with a purchased item should be ranked higher than any item of a non-purchased artist as long as ResNet50 agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__nonpurchased_sharingartist(artist_id, artwork_idxs_set):\n",
    "    candidate_idxs = artistId2artworkIndexes[artist_id]\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        i = random.choice(candidate_idxs)\n",
    "        if i not in artwork_idxs_set:\n",
    "            return i\n",
    "    return None # failed to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharingartist_visuallyacceptable_largeprofile(ui, pi):\n",
    "    artist_ids_set = users[ui].artist_ids_set\n",
    "    for _ in range(10): # try at most 10 times\n",
    "        ni = random.randint(0, n_artworks-1)\n",
    "        if artist_ids[ni] not in artist_ids_set and (\n",
    "            user2artwork_mindist[ui][pi] < user2artwork_mindist[ui][ni]):\n",
    "            return ni\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__rank_purchased_artist_above_nonpurchased_artist(instances_container, n_samples_per_user=500):\n",
    "    for ui, user in enumerate(users):\n",
    "        profile = user.artwork_idxs\n",
    "        profile_set = user.artwork_idxs_set\n",
    "        for _ in range(n_samples_per_user):\n",
    "            for __ in range(5):\n",
    "                aid = artist_ids[random.choice(profile)]\n",
    "                assert aid != -1\n",
    "                pi = sample_artwork_index__nonpurchased_sharingartist(aid, profile_set)\n",
    "                if pi is None: continue\n",
    "                ni = sample_artwork_index__notsharingartist_visuallyacceptable_largeprofile(ui, pi)\n",
    "                if ni is None: continue\n",
    "                if append_instance(instances_container, (profile, pi, ni, ui), pos_is_purchased=False):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "4987538 141413\n",
      "hash_collisions =  85437\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_purchased_artist_above_nonpurchased_artist(train_instances, n_samples_per_user=400)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__rank_purchased_artist_above_nonpurchased_artist(test_instances, n_samples_per_user=10)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Given all previous purchases, rank each  item of the next purchase basket higher than any item of non-purchased artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_rank_next(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        n = len(user.baskets)\n",
    "        if n <= 1:\n",
    "            continue\n",
    "        past_items = []\n",
    "        n_samples_per_basket = ceil(n_samples_per_user / (n-1))\n",
    "        for i in range(n-1):\n",
    "            cur_b = user.baskets[i]\n",
    "            for j in range(cur_b[0], cur_b[0] + cur_b[1]):\n",
    "                past_items.append(user.artwork_idxs[j])\n",
    "            next_b  = user.baskets[i+1]\n",
    "            profile = past_items.copy()\n",
    "            for _ in range(n_samples_per_basket):\n",
    "                for __ in range(5):\n",
    "                    pi = user.artwork_idxs[random.randint(next_b[0], next_b[0] + next_b[1] - 1)]\n",
    "                    ni = sample_artwork_index__notsharingartist_visuallyacceptable_largeprofile(ui, pi)\n",
    "                    if ni is None: continue\n",
    "                    if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "5715956 185475\n",
      "hash_collisions =  118379\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_past_rank_next(train_instances, n_samples_per_user=1000)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_past_rank_next(test_instances, n_samples_per_user=60)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Given only the present purchase basket, hide one and rank it higher than any item of non-purchased artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_present_hide_rank_one(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        n = sum(1 if b[1] >=2 else 0 for b in user.baskets)\n",
    "        if n == 0:\n",
    "            continue\n",
    "        n_samples_per_basket = ceil(n_samples_per_user / n)\n",
    "        for b in user.baskets:\n",
    "            if b[1] < 2:\n",
    "                continue\n",
    "            bs = b[0]\n",
    "            be = b[0] + b[1]\n",
    "            n_samples_per_item = ceil(n_samples_per_basket / b[1])\n",
    "            for i in range(bs, be):\n",
    "                profile = [user.artwork_idxs[j] for j in range(bs, be) if j != i]\n",
    "                assert len(profile) == be - bs - 1\n",
    "                assert len(profile) > 0                \n",
    "                pi = user.artwork_idxs[i]\n",
    "                for _ in range(n_samples_per_item):\n",
    "                    for __ in range(5):\n",
    "                        ni = sample_artwork_index__notsharingartist_visuallyacceptable_largeprofile(ui, pi)\n",
    "                        if ni is None: continue\n",
    "                        if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "6685275 199094\n",
      "hash_collisions =  158381\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_present_hide_rank_one(train_instances, n_samples_per_user=1500)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_present_hide_rank_one(test_instances, n_samples_per_user=20)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Given the past and the present, hide one and rank it higher than any item of non-purchased artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples__given_past_present_hide_rank_one(instances_container, n_samples_per_user=600):\n",
    "    for ui, user in enumerate(users):\n",
    "        if (len(user.baskets) < 2):\n",
    "            continue\n",
    "        u_baskets = user.baskets\n",
    "        u_artwork_idxs = user.artwork_idxs\n",
    "        n_baskets = len(u_baskets)\n",
    "        purchased = []\n",
    "        n_samples_per_basket = ceil(n_samples_per_user / (n_baskets-1))\n",
    "        for i in range(n_baskets):\n",
    "            b = u_baskets[i]\n",
    "            purchased.extend(u_artwork_idxs[j] for j in range(b[0], b[0] + b[1]))\n",
    "            if i == 0:\n",
    "                continue\n",
    "            assert len(purchased) == b[0] + b[1]\n",
    "            jmax = b[0] + (b[1] if b[1] >= 2 else 0)\n",
    "            assert jmax > 0\n",
    "            n_samples_per_item = ceil(n_samples_per_basket / jmax)\n",
    "            for j in range(jmax):\n",
    "                profile = [x for k,x in enumerate(purchased) if k != j]                \n",
    "                pi = u_artwork_idxs[j]\n",
    "                for _ in range(n_samples_per_item):\n",
    "                    for __ in range(5):\n",
    "                        ni = sample_artwork_index__notsharingartist_visuallyacceptable_largeprofile(ui, pi)\n",
    "                        if ni is None: continue\n",
    "                        if append_instance(instances_container, (profile, pi, ni, ui)):\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "sampling test instances ...\n",
      "7445804 251137\n",
      "hash_collisions =  187506\n",
      "visual_collisions =  0\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__given_past_present_hide_rank_one(train_instances, n_samples_per_user=1000)\n",
    "print('sampling test instances ...')\n",
    "generate_samples__given_past_present_hide_rank_one(test_instances, n_samples_per_user=20)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', _visual_collisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort train and test instances by profile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances.sort(key=lambda x: len(x[0]))\n",
    "test_instances.sort(key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatches(tuples, batch_size):\n",
    "    n_tuples = len(tuples)\n",
    "    n_batches = ceil(n_tuples / batch_size)\n",
    "    \n",
    "    print('n_tuples = ', n_tuples)\n",
    "    print('n_batches = ', n_batches)\n",
    "    \n",
    "    profile_indexes_batches = [None] * n_batches\n",
    "    profile_size_batches = [None] * n_batches\n",
    "    positive_index_batches = [None] * n_batches\n",
    "    negative_index_batches = [None] * n_batches\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        jmin = i * batch_size\n",
    "        jmax = min(jmin + batch_size, n_tuples)\n",
    "        actual_batch_size = jmax - jmin\n",
    "        \n",
    "        profile_maxlen = max(len(tuples[j][0]) for j in range(jmin, jmax))\n",
    "        profile_indexes_batch = np.full((actual_batch_size, profile_maxlen), 0, dtype=int)\n",
    "        profile_size_batch = np.empty((actual_batch_size,))\n",
    "        positive_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        negative_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        \n",
    "        for j in range(actual_batch_size):            \n",
    "            # profile indexes\n",
    "            for k,v in enumerate(tuples[jmin+j][0]):\n",
    "                profile_indexes_batch[j][k] = v\n",
    "            # profile size\n",
    "            profile_size_batch[j] = len(tuples[jmin+j][0])        \n",
    "            # positive index\n",
    "            positive_index_batch[j] = tuples[jmin+j][1]\n",
    "            # negative index\n",
    "            negative_index_batch[j] = tuples[jmin+j][2]\n",
    "            \n",
    "        profile_indexes_batches[i] = profile_indexes_batch\n",
    "        profile_size_batches[i] = profile_size_batch\n",
    "        positive_index_batches[i] = positive_index_batch\n",
    "        negative_index_batches[i] = negative_index_batch\n",
    "        \n",
    "    return dict(\n",
    "        profile_indexes_batches = profile_indexes_batches,\n",
    "        profile_size_batches    = profile_size_batches,\n",
    "        positive_index_batches  = positive_index_batches,\n",
    "        negative_index_batches  = negative_index_batches,\n",
    "        n_batches               = n_batches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_minibatches(minibatches):\n",
    "    profile_indexes_batches = minibatches['profile_indexes_batches']\n",
    "    profile_size_batches = minibatches['profile_size_batches']\n",
    "    positive_index_batches = minibatches['positive_index_batches']\n",
    "    negative_index_batches = minibatches['negative_index_batches']\n",
    "    n_batches = minibatches['n_batches']\n",
    "    assert n_batches == len(profile_indexes_batches)\n",
    "    assert n_batches == len(profile_size_batches)\n",
    "    assert n_batches == len(positive_index_batches)\n",
    "    assert n_batches == len(negative_index_batches)\n",
    "    assert n_batches > 0\n",
    "    \n",
    "    for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "        profile_indexes_batches,\n",
    "        profile_size_batches,\n",
    "        positive_index_batches,\n",
    "        negative_index_batches\n",
    "    ):\n",
    "        n = profile_size.shape[0]\n",
    "        assert n == profile_indexes.shape[0]\n",
    "        assert n == positive_index.shape[0]\n",
    "        assert n == negative_index.shape[0]\n",
    "        \n",
    "        for i in range(n):\n",
    "            assert positive_index[i] != negative_index[i]\n",
    "            psz = int(profile_size[i])\n",
    "            m = profile_indexes[i].shape[0]\n",
    "            assert psz <= m\n",
    "            for j in range(psz, m):\n",
    "                assert profile_indexes[i][j] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Networks import ContentBasedLearn2RankNetwork_Train, TrainLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(train_minibatches, test_minibatches,\n",
    "                  n_train_instances, n_test_instances, batch_size,\n",
    "                  max_seconds_training=3600,\n",
    "                  min_seconds_to_check_improvement=60,\n",
    "                  early_stopping_checks=4,\n",
    "                  learning_rates=[1e-3]):\n",
    "    \n",
    "    n_train_batches = train_minibatches['n_batches']\n",
    "    n_test_batches = test_minibatches['n_batches']\n",
    "    \n",
    "    print('learning_rates = ', learning_rates)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        network = ContentBasedLearn2RankNetwork_Train(user_model_mode='BIGGER')\n",
    "        with tf.Session() as sess:\n",
    "            try:\n",
    "                saver = tf.train.Saver()            \n",
    "                saver.restore(sess, tf.train.latest_checkpoint(MODEL_PATH))\n",
    "                print('model successfully restored from checkpoint!')\n",
    "            except ValueError:\n",
    "                print('no checkpoint found: initializing variables with random values')\n",
    "                os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "                sess.run(tf.global_variables_initializer())            \n",
    "            trainlogger = TrainLogger(MODEL_PATH + 'train_logs.csv')\n",
    "\n",
    "            # ========= BEFORE TRAINING ============\n",
    "            \n",
    "            initial_test_acc = 0.\n",
    "            for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
    "                test_minibatches['profile_indexes_batches'],\n",
    "                test_minibatches['profile_size_batches'],\n",
    "                test_minibatches['positive_index_batches'],\n",
    "                test_minibatches['negative_index_batches']\n",
    "            ):\n",
    "                minibatch_test_acc = network.get_test_accuracy(\n",
    "                    sess, resnet50_embeddings, profile_indexes, profile_size, positive_index, negative_index)\n",
    "                initial_test_acc += minibatch_test_acc\n",
    "            initial_test_acc /= n_test_instances\n",
    "\n",
    "            print(\"Before training: test_accuracy = %f\" % initial_test_acc)\n",
    "            \n",
    "            best_test_acc = initial_test_acc\n",
    "            seconds_training = 0\n",
    "            elapsed_seconds_from_last_check = 0\n",
    "            checks_with_no_improvement = 0\n",
    "            last_improvement_loss = None\n",
    "            \n",
    "            # ========= TRAINING ============\n",
    "            \n",
    "            print ('Starting training ...')\n",
    "            n_lr = len(learning_rates)\n",
    "            lr_i = 0\n",
    "            train_loss_ema = 0. # exponential moving average\n",
    "            \n",
    "            while seconds_training < max_seconds_training:\n",
    "                \n",
    "                for train_i, (profile_indexes, profile_size, positive_index, negative_index) in enumerate(zip(\n",
    "                    train_minibatches['profile_indexes_batches'],\n",
    "                    train_minibatches['profile_size_batches'],\n",
    "                    train_minibatches['positive_index_batches'],\n",
    "                    train_minibatches['negative_index_batches']\n",
    "                )):\n",
    "                    # optimize and get traing loss\n",
    "                    start_t = time.time()\n",
    "                    _, minibatch_train_loss = network.optimize_and_get_train_loss(\n",
    "                        sess, learning_rates[lr_i], resnet50_embeddings, profile_indexes,\n",
    "                        profile_size, positive_index, negative_index)\n",
    "                    delta_t = time.time() - start_t\n",
    "                    \n",
    "                    # update train loss exponential moving average\n",
    "                    train_loss_ema = 0.999 * train_loss_ema + 0.001 * minibatch_train_loss\n",
    "                    \n",
    "                    # update time tracking variables\n",
    "                    seconds_training += delta_t\n",
    "                    elapsed_seconds_from_last_check += delta_t\n",
    "                    \n",
    "                    # check for improvements using test set if it's time to do so\n",
    "                    if elapsed_seconds_from_last_check >= min_seconds_to_check_improvement:\n",
    "                        \n",
    "                        # --- testing\n",
    "                        test_acc = 0.\n",
    "                        for _profile_indexes, _profile_size, _positive_index, _negative_index in zip(\n",
    "                            test_minibatches['profile_indexes_batches'],\n",
    "                            test_minibatches['profile_size_batches'],\n",
    "                            test_minibatches['positive_index_batches'],\n",
    "                            test_minibatches['negative_index_batches']\n",
    "                        ):\n",
    "                            minibatch_test_acc = network.get_test_accuracy(\n",
    "                                sess, resnet50_embeddings, _profile_indexes,\n",
    "                                _profile_size, _positive_index, _negative_index)                            \n",
    "                            test_acc += minibatch_test_acc\n",
    "                        test_acc /= n_test_instances\n",
    "                    \n",
    "                        print((\"train_i=%d, train_loss = %.12f, test_accuracy = %.5f,\"\n",
    "                               \" check_secs = %.2f, total_secs = %.2f\") % (\n",
    "                                train_i, train_loss_ema, test_acc, elapsed_seconds_from_last_check, seconds_training))                        \n",
    "                        \n",
    "                        # check for improvements\n",
    "                        if (test_acc > best_test_acc) or (\n",
    "                            test_acc == best_test_acc and (\n",
    "                                last_improvement_loss is not None and\\\n",
    "                                last_improvement_loss > train_loss_ema\n",
    "                            )\n",
    "                        ):  \n",
    "                            last_improvement_loss = train_loss_ema\n",
    "                            best_test_acc = test_acc\n",
    "                            checks_with_no_improvement = 0\n",
    "                            saver = tf.train.Saver()\n",
    "                            save_path = saver.save(sess, MODEL_PATH)                    \n",
    "                            print(\"   ** improvement detected: model saved to path \", save_path)\n",
    "                            model_updated = True\n",
    "                        else:\n",
    "                            checks_with_no_improvement += 1                            \n",
    "                            model_updated = False\n",
    "\n",
    "                        # --- logging ---                        \n",
    "                        trainlogger.log_update(\n",
    "                            train_loss_ema, test_acc, n_train_instances, n_test_instances,\n",
    "                            elapsed_seconds_from_last_check, batch_size, learning_rates[lr_i], 't' if model_updated else 'f')\n",
    "                        \n",
    "                        # --- check for early stopping\n",
    "                        if checks_with_no_improvement >= early_stopping_checks:\n",
    "                            if lr_i + 1 < len(learning_rates):\n",
    "                                lr_i += 1\n",
    "                                checks_with_no_improvement = 0\n",
    "                                print(\"   *** %d checks with no improvements -> using a smaller learning_rate = %f\" % (\n",
    "                                    early_stopping_checks, learning_rates[lr_i]))\n",
    "                            else:\n",
    "                                print(\"   *** %d checks with no improvements -> early stopping :(\" % early_stopping_checks)\n",
    "                                return\n",
    "                        \n",
    "                        # --- reset check variables\n",
    "                        elapsed_seconds_from_last_check = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  7445804\n",
      "n_batches =  3636\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 2048\n",
    "train_minibatches = generate_minibatches(train_instances, train_batch_size)\n",
    "sanity_check_minibatches(train_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  251137\n",
      "n_batches =  123\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 2048\n",
    "test_minibatches = generate_minibatches(test_instances, test_batch_size)\n",
    "sanity_check_minibatches(test_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rates =  [0.0001, 3.33e-05, 1e-05, 3.33e-06, 1e-06]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "model successfully restored from checkpoint!\n",
      "Before training: test_accuracy = 0.998129\n",
      "Starting training ...\n",
      "train_i=1915, train_loss = 0.005370066157, test_accuracy = 0.99640, check_secs = 180.01, total_secs = 180.01\n",
      "train_i=138, train_loss = 0.031004245594, test_accuracy = 0.99750, check_secs = 180.07, total_secs = 360.08\n",
      "train_i=2057, train_loss = 0.007360850512, test_accuracy = 0.99739, check_secs = 180.09, total_secs = 540.17\n",
      "train_i=278, train_loss = 0.007656113307, test_accuracy = 0.99795, check_secs = 180.00, total_secs = 720.18\n",
      "   *** 4 checks with no improvements -> using a smaller learning_rate = 0.000033\n",
      "train_i=2197, train_loss = 0.002553315991, test_accuracy = 0.99845, check_secs = 180.03, total_secs = 900.21\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=417, train_loss = 0.003544851454, test_accuracy = 0.99852, check_secs = 180.01, total_secs = 1080.23\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=2334, train_loss = 0.001377544919, test_accuracy = 0.99855, check_secs = 180.01, total_secs = 1260.24\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=555, train_loss = 0.002468414482, test_accuracy = 0.99868, check_secs = 180.04, total_secs = 1440.27\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=2473, train_loss = 0.000881615360, test_accuracy = 0.99870, check_secs = 180.02, total_secs = 1620.29\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=696, train_loss = 0.001817777528, test_accuracy = 0.99887, check_secs = 180.09, total_secs = 1800.38\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=2614, train_loss = 0.000568731922, test_accuracy = 0.99861, check_secs = 180.04, total_secs = 1980.43\n",
      "train_i=835, train_loss = 0.001503067978, test_accuracy = 0.99894, check_secs = 180.00, total_secs = 2160.43\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=2752, train_loss = 0.000467948710, test_accuracy = 0.99867, check_secs = 180.09, total_secs = 2340.52\n",
      "train_i=975, train_loss = 0.001192074108, test_accuracy = 0.99877, check_secs = 180.04, total_secs = 2520.55\n",
      "train_i=2890, train_loss = 0.000396654558, test_accuracy = 0.99859, check_secs = 180.00, total_secs = 2700.56\n",
      "train_i=1115, train_loss = 0.000936327863, test_accuracy = 0.99894, check_secs = 180.05, total_secs = 2880.61\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=3028, train_loss = 0.000297267601, test_accuracy = 0.99899, check_secs = 180.01, total_secs = 3060.62\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=1255, train_loss = 0.000686415385, test_accuracy = 0.99900, check_secs = 180.06, total_secs = 3240.68\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=3166, train_loss = 0.000329282009, test_accuracy = 0.99875, check_secs = 180.02, total_secs = 3420.69\n",
      "train_i=1395, train_loss = 0.000505673814, test_accuracy = 0.99898, check_secs = 180.06, total_secs = 3600.75\n",
      "train_i=3303, train_loss = 0.000304859293, test_accuracy = 0.99885, check_secs = 180.07, total_secs = 3780.83\n",
      "train_i=1536, train_loss = 0.000368604817, test_accuracy = 0.99894, check_secs = 180.03, total_secs = 3960.86\n",
      "   *** 4 checks with no improvements -> using a smaller learning_rate = 0.000010\n",
      "train_i=3439, train_loss = 0.000310226138, test_accuracy = 0.99916, check_secs = 180.04, total_secs = 4140.89\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=1676, train_loss = 0.000218277549, test_accuracy = 0.99928, check_secs = 180.07, total_secs = 4320.96\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=3573, train_loss = 0.000295641031, test_accuracy = 0.99916, check_secs = 180.01, total_secs = 4500.97\n",
      "train_i=1817, train_loss = 0.000140465788, test_accuracy = 0.99931, check_secs = 180.06, total_secs = 4681.02\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=38, train_loss = 0.000366201401, test_accuracy = 0.99920, check_secs = 180.09, total_secs = 4861.11\n",
      "train_i=1959, train_loss = 0.000098406475, test_accuracy = 0.99928, check_secs = 180.09, total_secs = 5041.20\n",
      "train_i=182, train_loss = 0.000240057629, test_accuracy = 0.99920, check_secs = 180.05, total_secs = 5221.26\n",
      "train_i=2101, train_loss = 0.000070526250, test_accuracy = 0.99926, check_secs = 180.09, total_secs = 5401.35\n",
      "   *** 4 checks with no improvements -> using a smaller learning_rate = 0.000003\n",
      "train_i=322, train_loss = 0.000201968294, test_accuracy = 0.99928, check_secs = 180.04, total_secs = 5581.39\n",
      "train_i=2241, train_loss = 0.000065905241, test_accuracy = 0.99936, check_secs = 180.06, total_secs = 5761.45\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=462, train_loss = 0.000143055158, test_accuracy = 0.99932, check_secs = 180.03, total_secs = 5941.48\n",
      "train_i=2379, train_loss = 0.000049405329, test_accuracy = 0.99935, check_secs = 180.06, total_secs = 6121.54\n",
      "train_i=600, train_loss = 0.000106463325, test_accuracy = 0.99931, check_secs = 180.05, total_secs = 6301.59\n",
      "train_i=2519, train_loss = 0.000041673723, test_accuracy = 0.99933, check_secs = 180.01, total_secs = 6481.60\n",
      "   *** 4 checks with no improvements -> using a smaller learning_rate = 0.000001\n",
      "train_i=740, train_loss = 0.000108877066, test_accuracy = 0.99932, check_secs = 180.08, total_secs = 6661.68\n",
      "train_i=2656, train_loss = 0.000042310806, test_accuracy = 0.99937, check_secs = 180.02, total_secs = 6841.70\n",
      "   ** improvement detected: model saved to path  /mnt/workspace/pamessina_models/ugallery/youtube_like/v5_usermodelbigger/\n",
      "train_i=879, train_loss = 0.000101715901, test_accuracy = 0.99935, check_secs = 180.02, total_secs = 7021.73\n",
      "train_i=2795, train_loss = 0.000044002866, test_accuracy = 0.99935, check_secs = 180.02, total_secs = 7201.74\n",
      "train_i=1021, train_loss = 0.000097787490, test_accuracy = 0.99934, check_secs = 180.04, total_secs = 7381.78\n",
      "train_i=2935, train_loss = 0.000039697767, test_accuracy = 0.99935, check_secs = 180.06, total_secs = 7561.84\n",
      "   *** 4 checks with no improvements -> early stopping :(\n"
     ]
    }
   ],
   "source": [
    "train_network(\n",
    "    train_minibatches, test_minibatches,\n",
    "    len(train_instances), len(test_instances), train_batch_size,\n",
    "    max_seconds_training=3600 * 4,\n",
    "    min_seconds_to_check_improvement=180,\n",
    "    early_stopping_checks=4,\n",
    "    learning_rates=[1e-4, 3.33e-5, 1e-5, 3.33e-6, 1e-6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
