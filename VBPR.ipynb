{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport utils, Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from math import ceil\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import load_embeddings_and_ids, concatenate_featmats, User, VisualSimilarityHandler, get_decaying_learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a single GPU because we want to be nice with other people :)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load pre-trained image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = load_embeddings_and_ids('/mnt/workspace/Ugallery/ResNet50/', 'flatten_1.npy', 'ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet = load_embeddings_and_ids('/mnt/workspace/Ugallery/AlexNet/', 'fc7.npy', 'ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inceptionv3 = load_embeddings_and_ids('/mnt/workspace/Ugallery/InceptionV3/', 'avg_pool.npy', 'ids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Concatenate embeddings + z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = [\n",
    "    resnet50,\n",
    "#     alexnet,\n",
    "#     inceptionv3,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13297"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artwork_ids_set = set()\n",
    "for embedding in embedding_list:\n",
    "    artwork_ids_set.update(embedding['index2id'])\n",
    "artwork_ids = list(artwork_ids_set)\n",
    "artwork_id2index = {_id:i for i,_id in enumerate(artwork_ids)}\n",
    "n_artworks = len(artwork_ids)\n",
    "n_artworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featmat_list = [tmp['featmat'] for tmp in embedding_list]\n",
    "id2index_list = [tmp['id2index'] for tmp in embedding_list]\n",
    "concat_featmat = concatenate_featmats(artwork_ids, featmat_list, id2index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_featmat = StandardScaler().fit_transform(concat_featmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 2048)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_featmat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/mnt/workspace/Ugallery/Clustering/artworkId2clusterId(resnet50+alexnet+inceptionv3+vgg19+incepresv2).json') as f:\n",
    "with open('/mnt/workspace/Ugallery/Clustering/artworkId2clusterId(resnet50).json') as f:\n",
    "    artworkId2clusterId = json.load(f)\n",
    "cluster_ids = np.full((n_artworks,), -1, dtype=int)\n",
    "for k, v in artworkId2clusterId.items():\n",
    "    cluster_ids[artwork_id2index[int(k)]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 99, (13297,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_ids.min(), cluster_ids.max(), cluster_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters = len(set(cluster_ids))\n",
    "n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterId2artworkIndexes = [[] for _ in range(n_clusters)]\n",
    "for i, cluster_id in enumerate(cluster_ids):\n",
    "    clusterId2artworkIndexes[cluster_id].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load PCA200 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca200 = load_embeddings_and_ids(\n",
    "#     '/mnt/workspace/Ugallery/PCA200(resnet50+alexnet+inceptionv3+vgg19+incepresv2)/',\n",
    "    '/mnt/workspace/Ugallery/PCA200(resnet50)/',\n",
    "    'embeddings.npy',\n",
    "    'ids.npy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca200_embeddings = pca200['featmat']\n",
    "pca200_index2id = pca200['index2id']\n",
    "pca200_id2index = pca200['id2index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca200_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(artwork_ids, pca200_index2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('./data/valid_sales.csv')\n",
    "artworks_df = pd.read_csv('./data/valid_artworks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_ids = np.full((n_artworks,), -1, dtype=int)\n",
    "for _artworkId, _artistId in zip(artworks_df.id, artworks_df.artist_id):\n",
    "    i = artwork_id2index[_artworkId]\n",
    "    artist_ids[i] = _artistId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistId2artworkIndexes = dict()\n",
    "for i, _artistId in enumerate(artist_ids):\n",
    "    if _artistId == -1:\n",
    "        continue\n",
    "    try:\n",
    "        artistId2artworkIndexes[_artistId].append(i)\n",
    "    except KeyError:\n",
    "        artistId2artworkIndexes[_artistId] = [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect transactions per user (making sure we hide the last nonfirst purchase basket per user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2919"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = sales_df.customer_id.unique()\n",
    "user_id2index = { _id:i for i,_id in enumerate(user_ids) }\n",
    "users = [User(uid) for uid in user_ids]\n",
    "n_users = len(user_ids)\n",
    "n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect and sanity check transactions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sales_df = sales_df.sort_values('order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear structures to prevent possible duplicate elements\n",
    "for user in users:\n",
    "    user.clear()\n",
    "\n",
    "# collect transactions per user sorted by timestamp\n",
    "for uid, aid, t in zip(sorted_sales_df.customer_id,\n",
    "                       sorted_sales_df.artwork_id,\n",
    "                       sorted_sales_df.order_date):\n",
    "    users[user_id2index[uid]].append_transaction(\n",
    "        aid, t, artwork_id2index, artist_ids, cluster_ids)\n",
    "    assert users[user_id2index[uid]]._uid == uid\n",
    "    \n",
    "# bin transctions with same timestamps into purchase baskets\n",
    "for user in users:\n",
    "    user.build_purchase_baskets()\n",
    "    user.sanity_check_purchase_baskets()\n",
    "    user.remove_last_nonfirst_purchase_basket(\n",
    "        artwork_id2index, artist_ids, cluster_ids)\n",
    "    user.sanity_check_purchase_baskets()\n",
    "    user.refresh_nonpurchased_cluster_ids(n_clusters)\n",
    "    user.refresh_cluster_ids()\n",
    "    user.refresh_artist_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_triple(ui, pi, ni):\n",
    "    return  ((pi * n_artworks) + ni) * n_users + ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_instance(instance,\n",
    "                          pos_in_profile=True,\n",
    "                          pos_sharing_cluster_artist=None,\n",
    "                          neg_notsharing_artist=None,\n",
    "                          neg_notsharing_artist_cluster=None,\n",
    "                         ):\n",
    "    ui, pi, ni = instance    \n",
    "    try:\n",
    "        assert 0 <= ui < n_users\n",
    "        assert 0 <= pi < n_artworks\n",
    "        assert 0 <= ni < n_artworks\n",
    "        assert pi != ni\n",
    "        assert not vissimhandler.same(pi,ni)\n",
    "        \n",
    "        assert 0 <= ui < n_users\n",
    "        user = users[ui]\n",
    "        \n",
    "        if pos_in_profile is True:\n",
    "            assert pi in user.artwork_idxs_set\n",
    "        elif pos_in_profile is False:\n",
    "            assert pi not in user.artwork_idxs_set\n",
    "            \n",
    "        if pos_sharing_cluster_artist:\n",
    "            assert artist_ids[pi] in user.artist_ids_set\n",
    "            assert cluster_ids[pi] in user.cluster_ids_set\n",
    "            \n",
    "        assert ni not in user.artwork_idxs_set\n",
    "        if neg_notsharing_artist:\n",
    "            assert artist_ids[ni] not in user.artist_ids_set\n",
    "        if neg_notsharing_artist_cluster:\n",
    "            assert artist_ids[ni] not in user.artist_ids_set\n",
    "            assert cluster_ids[ni] not in user.cluster_ids_set            \n",
    "    except AssertionError:\n",
    "        print('ui = ', ui)\n",
    "        print('pi = ', pi)\n",
    "        print('ni = ', ni)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_instance(container, instance, **kwargs):\n",
    "    global _hash_collisions\n",
    "    ui, pi, ni = instance\n",
    "    \n",
    "    h = hash_triple(ui, pi, ni)\n",
    "    if h in used_hashes:\n",
    "        _hash_collisions += 1\n",
    "        return False\n",
    "    \n",
    "    if vissimhandler.same(pi, ni):\n",
    "        return False\n",
    "    \n",
    "    sanity_check_instance(instance, **kwargs)\n",
    "    container.append(instance)\n",
    "    used_hashes.add(h)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_samples(sampler_func):\n",
    "    def wrapper(instances_container, n_samples):\n",
    "        len_before = len(instances_container)\n",
    "        sampler_func(instances_container, n_samples)\n",
    "        actual_samples = len(instances_container) - len_before\n",
    "        print('  target samples: %d' % n_samples)\n",
    "        print('  actual samples: %d' % actual_samples)\n",
    "        print('  delta: %d' % (n_samples - actual_samples))\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vissimhandler = VisualSimilarityHandler(cluster_ids, pca200_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vissimhandler.count = 0\n",
    "used_hashes = set()\n",
    "_hash_collisions = 0\n",
    "train_instances = []\n",
    "test_instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000000, 200000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_STRATEGIES = 2\n",
    "TOTAL_SAMPLES__TRAIN = 10000000\n",
    "TOTAL_SAMPLES__TEST =  400000\n",
    "N_SAMPLES_PER_STRATEGY__TRAIN = int(TOTAL_SAMPLES__TRAIN / N_STRATEGIES)\n",
    "N_SAMPLES_PER_STRATEGY__TEST = int(TOTAL_SAMPLES__TEST / N_STRATEGIES)\n",
    "N_SAMPLES_PER_STRATEGY__TRAIN, N_SAMPLES_PER_STRATEGY__TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_GRAINED_THRESHOLD = 0.6\n",
    "VISUAL_CONFIDENCE_THRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original BPR strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) given profile, recommend profile\n",
    "Given a user's profile, all items in the profile should be ranked higher than items outside the profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__outsideprofile(profile_set, pi):\n",
    "    while True:\n",
    "        if random.random() <= FINE_GRAINED_THRESHOLD:\n",
    "            ni = random.choice(clusterId2artworkIndexes[cluster_ids[pi]])\n",
    "        else:            \n",
    "            c = random.randint(0, n_clusters-1)\n",
    "            ni = random.choice(clusterId2artworkIndexes[c])\n",
    "        if ni not in profile_set:\n",
    "            return ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@print_num_samples\n",
    "def generate_samples__rank_profile_above_nonprofile(instances_container, n_samples):\n",
    "    n_samples_per_user = ceil(n_samples / n_users)    \n",
    "    for ui, user in enumerate(users):\n",
    "        profile = user.artwork_idxs\n",
    "        profile_set = user.artwork_idxs_set\n",
    "        for _ in range(n_samples_per_user):\n",
    "            for __ in range(5):\n",
    "                pi = random.choice(profile)\n",
    "                ni = sample_artwork_index__outsideprofile(profile_set, pi)\n",
    "                if append_instance(instances_container, (ui, pi, ni)):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "  target samples: 4155\n",
      "  actual samples: 5180\n",
      "  delta: -1025\n",
      "5001025 201834\n",
      "hash_collisions =  6790839\n",
      "visual_collisions =  228\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_profile_above_nonprofile(\n",
    "#     train_instances, n_samples=N_SAMPLES_PER_STRATEGY__TRAIN)\n",
    "    train_instances, n_samples=4155)\n",
    "# print('sampling test instances ...')\n",
    "# generate_samples__rank_profile_above_nonprofile(\n",
    "# #     test_instances, n_samples=N_SAMPLES_PER_STRATEGY__TEST)\n",
    "#     test_instances, n_samples=728)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', vissimhandler.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain-specific strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Recommend visually similar items from favorite artists\n",
    "Given a user, any item outside the user's profile that shares artist and visual cluster with items in the user's profile should be ranked higher than any item from an artist and visual cluster not present in the user's profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__outsideprofile__sharing_artist_cluster(profile_set, artists_list, clusters_set):\n",
    "    for _ in range(20): # try at most 20 times\n",
    "        # sharing artist\n",
    "        a = random.choice(artists_list)\n",
    "        i = random.choice(artistId2artworkIndexes[a])\n",
    "        # sharing cluster\n",
    "        if cluster_ids[i] not in clusters_set: continue\n",
    "        # oustide profile\n",
    "        if i in profile_set: continue\n",
    "        # done\n",
    "        return i\n",
    "    return None # failed to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_artwork_index__notsharing_artist_cluster(artists_set, nonused_clusters_list):\n",
    "    while True:\n",
    "        # not sharing cluster\n",
    "        c = random.choice(nonused_clusters_list)\n",
    "        i = random.choice(clusterId2artworkIndexes[c])\n",
    "        # not sharing artist\n",
    "        if artist_ids[i] not in artists_set:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@print_num_samples\n",
    "def generate_samples__rank_sharing_artist_cluster_above_notsharing_artist_cluster(instances_container, n_samples):\n",
    "    n_samples_per_user = ceil(n_samples / n_users)    \n",
    "    for ui, user in enumerate(users):\n",
    "        profile = user.artwork_idxs\n",
    "        profile_set = user.artwork_idxs_set\n",
    "        artists_list = user.artist_ids\n",
    "        artists_set = user.artist_ids_set\n",
    "        clusters_set = user.cluster_ids_set\n",
    "        nonused_clusters_list = user.nonp_cluster_ids\n",
    "        for _ in range(n_samples_per_user):\n",
    "            for __ in range(5):\n",
    "                pi = sample_artwork_index__outsideprofile__sharing_artist_cluster(profile_set, artists_list, clusters_set)\n",
    "                if pi is None: continue\n",
    "                ni = sample_artwork_index__notsharing_artist_cluster(artists_set, nonused_clusters_list)\n",
    "                if append_instance(instances_container, (ui, pi, ni),\n",
    "                                   pos_in_profile=False,\n",
    "                                   pos_sharing_cluster_artist=True,\n",
    "                                   neg_notsharing_artist_cluster=True,\n",
    "                                  ):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling train instances ...\n",
      "  target samples: 3908\n",
      "  actual samples: 4372\n",
      "  delta: -464\n",
      "10001489 403310\n",
      "hash_collisions =  7004532\n",
      "visual_collisions =  228\n"
     ]
    }
   ],
   "source": [
    "print('sampling train instances ...')\n",
    "generate_samples__rank_sharing_artist_cluster_above_notsharing_artist_cluster(\n",
    "#     train_instances, n_samples=N_SAMPLES_PER_STRATEGY__TRAIN)\n",
    "    train_instances, n_samples=3908)\n",
    "# print('sampling test instances ...')\n",
    "# generate_samples__rank_sharing_artist_cluster_above_notsharing_artist_cluster(\n",
    "# #     test_instances, n_samples=N_SAMPLES_PER_STRATEGY__TEST)\n",
    "#     test_instances, n_samples=703)\n",
    "print(len(train_instances), len(test_instances))\n",
    "print('hash_collisions = ', _hash_collisions)\n",
    "print('visual_collisions = ', vissimhandler.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffle train instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatches(tuples, batch_size):\n",
    "    n_tuples = len(tuples)\n",
    "    n_batches = ceil(n_tuples / batch_size)\n",
    "    \n",
    "    assert n_batches * batch_size >= n_tuples\n",
    "    assert (n_batches - 1) * batch_size < n_tuples\n",
    "    \n",
    "    indexes = list(range(n_tuples))\n",
    "    random.shuffle(indexes)\n",
    "    \n",
    "    print('n_tuples = ', n_tuples)\n",
    "    print('n_batches = ', n_batches)\n",
    "    \n",
    "    user_index_batches = [None] * n_batches\n",
    "    pos_index_batches = [None] * n_batches\n",
    "    neg_index_batches = [None] * n_batches\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        jmin = i * batch_size\n",
    "        jmax = min(jmin + batch_size, n_tuples)\n",
    "        actual_batch_size = jmax - jmin\n",
    "        \n",
    "        user_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        pos_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        neg_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
    "        \n",
    "        for j in range(actual_batch_size):\n",
    "            t = tuples[indexes[jmin+j]]\n",
    "            user_index_batch[j] = t[0]\n",
    "            pos_index_batch[j] = t[1]\n",
    "            neg_index_batch[j] = t[2]\n",
    "\n",
    "        user_index_batches[i] = user_index_batch\n",
    "        pos_index_batches[i] = pos_index_batch\n",
    "        neg_index_batches[i] = neg_index_batch\n",
    "        \n",
    "    return dict(\n",
    "        user_index_batches = user_index_batches,\n",
    "        pos_index_batches  = pos_index_batches,\n",
    "        neg_index_batches  = neg_index_batches,\n",
    "        n_batches          = n_batches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_minibatches(minibatches):\n",
    "    user_index_batches = minibatches['user_index_batches']\n",
    "    pos_index_batches = minibatches['pos_index_batches']\n",
    "    neg_index_batches = minibatches['neg_index_batches']\n",
    "    n_batches = minibatches['n_batches']\n",
    "    assert n_batches == len(user_index_batches)\n",
    "    assert n_batches == len(pos_index_batches)\n",
    "    assert n_batches == len(neg_index_batches)\n",
    "    assert n_batches > 0\n",
    "    \n",
    "    for user_index, pos_index, neg_index in zip(\n",
    "        user_index_batches,\n",
    "        pos_index_batches,\n",
    "        neg_index_batches\n",
    "    ):\n",
    "        n = user_index.shape[0]\n",
    "        assert n == pos_index.shape[0]\n",
    "        assert n == neg_index.shape[0]\n",
    "        \n",
    "        for i in range(n):\n",
    "            ui = user_index[i]\n",
    "            pi = pos_index[i]\n",
    "            ni = neg_index[i]\n",
    "            assert pi != ni\n",
    "            assert ni not in users[ui].artwork_idxs_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Networks import VBPR_Network_Train, TrainLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(train_minibatches, test_minibatches,\n",
    "                  n_train_instances, n_test_instances, batch_size,\n",
    "                  pretrained_embeddings,\n",
    "                  user_latent_dim,\n",
    "                  item_latent_dim,\n",
    "                  item_visual_dim,\n",
    "                  model_path,\n",
    "                  max_seconds_training=3600,\n",
    "                  min_seconds_to_check_improvement=60,\n",
    "                  early_stopping_checks=4,\n",
    "                  weight_decay=0.001,\n",
    "                  learning_rates=[1e-3]):\n",
    "    \n",
    "    n_train_batches = train_minibatches['n_batches']\n",
    "    n_test_batches = test_minibatches['n_batches']\n",
    "    \n",
    "    print('learning_rates = ', learning_rates)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        network = VBPR_Network_Train(\n",
    "            n_users=n_users,\n",
    "            n_items=n_artworks,\n",
    "            user_latent_dim=user_latent_dim,\n",
    "            item_latent_dim=item_latent_dim,\n",
    "            item_visual_dim=item_visual_dim,            \n",
    "            pretrained_dim=pretrained_embeddings.shape[1],\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "        \n",
    "        print('Variables to be trained:')\n",
    "        for x in tf.global_variables():\n",
    "            print('\\t', x)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            try:\n",
    "                saver = tf.train.Saver()            \n",
    "                saver.restore(sess, tf.train.latest_checkpoint(model_path))\n",
    "                print('model successfully restored from checkpoint!')\n",
    "            except ValueError:\n",
    "                print('no checkpoint found: initializing variables with random values')\n",
    "                os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "                sess.run(tf.global_variables_initializer())            \n",
    "            trainlogger = TrainLogger(model_path + 'train_logs.csv')\n",
    "\n",
    "            # ========= BEFORE TRAINING ============\n",
    "            \n",
    "            initial_test_acc = 0.            \n",
    "            for user_index, pos_index, neg_index in zip(\n",
    "                test_minibatches['user_index_batches'],\n",
    "                test_minibatches['pos_index_batches'],\n",
    "                test_minibatches['neg_index_batches']\n",
    "            ):\n",
    "                minibatch_test_acc = network.get_test_accuracy(\n",
    "                    sess, pretrained_embeddings, user_index, pos_index, neg_index)\n",
    "                initial_test_acc += minibatch_test_acc\n",
    "            initial_test_acc /= n_test_instances\n",
    "\n",
    "            print(\"Before training: test_accuracy = %f\" % initial_test_acc)\n",
    "            \n",
    "            best_test_acc = initial_test_acc\n",
    "            seconds_training = 0\n",
    "            elapsed_seconds_from_last_check = 0\n",
    "            checks_with_no_improvement = 0\n",
    "            last_improvement_loss = None\n",
    "            \n",
    "            # ========= TRAINING ============\n",
    "            \n",
    "            print ('Starting training ...')\n",
    "            n_lr = len(learning_rates)\n",
    "            lr_i = 0\n",
    "            train_loss_ema = None # exponential moving average\n",
    "            \n",
    "            while seconds_training < max_seconds_training:\n",
    "                \n",
    "                for train_i, (user_index, pos_index, neg_index) in enumerate(zip(\n",
    "                    train_minibatches['user_index_batches'],\n",
    "                    train_minibatches['pos_index_batches'],\n",
    "                    train_minibatches['neg_index_batches']\n",
    "                )):\n",
    "                    # optimize and get traing loss\n",
    "                    start_t = time.time()\n",
    "                    _, minibatch_train_loss = network.optimize_and_get_train_loss(\n",
    "                        sess, pretrained_embeddings, user_index, pos_index, neg_index, learning_rates[lr_i])\n",
    "                    delta_t = time.time() - start_t\n",
    "                    \n",
    "                    # update train loss exponential moving average\n",
    "                    train_loss_ema = minibatch_train_loss if train_loss_ema is None else\\\n",
    "                                    0.999 * train_loss_ema + 0.001 * minibatch_train_loss\n",
    "                    \n",
    "                    # update time tracking variables\n",
    "                    seconds_training += delta_t\n",
    "                    elapsed_seconds_from_last_check += delta_t\n",
    "                    \n",
    "                    # check for improvements using test set if it's time to do so\n",
    "                    if elapsed_seconds_from_last_check >= min_seconds_to_check_improvement:\n",
    "                        \n",
    "                        # --- testing                        \n",
    "                        test_acc = 0.\n",
    "                        for _user_index, _pos_index, _neg_index in zip(\n",
    "                            test_minibatches['user_index_batches'],\n",
    "                            test_minibatches['pos_index_batches'],\n",
    "                            test_minibatches['neg_index_batches']\n",
    "                        ):\n",
    "                            minibatch_test_acc = network.get_test_accuracy(\n",
    "                                sess, pretrained_embeddings, _user_index, _pos_index, _neg_index)\n",
    "                            test_acc += minibatch_test_acc\n",
    "                        test_acc /= n_test_instances\n",
    "                    \n",
    "                        print((\"train_i=%d, train_loss = %.12f, test_accuracy = %.6f,\"\n",
    "                               \" check_secs = %.2f, total_secs = %.2f\") % (\n",
    "                                train_i, train_loss_ema, test_acc, elapsed_seconds_from_last_check, seconds_training))                        \n",
    "                        \n",
    "                        # check for improvements\n",
    "                        if (test_acc > best_test_acc) or (\n",
    "                            test_acc == best_test_acc and (\n",
    "                                last_improvement_loss is not None and\\\n",
    "                                last_improvement_loss > train_loss_ema\n",
    "                            )\n",
    "                        ):  \n",
    "                            last_improvement_loss = train_loss_ema\n",
    "                            best_test_acc = test_acc\n",
    "                            checks_with_no_improvement = 0\n",
    "                            saver = tf.train.Saver()\n",
    "                            save_path = saver.save(sess, MODEL_PATH)                    \n",
    "                            print(\"   ** improvement detected: model saved to path \", save_path)\n",
    "                            model_updated = True\n",
    "                        else:\n",
    "                            checks_with_no_improvement += 1                            \n",
    "                            model_updated = False\n",
    "\n",
    "                        # --- logging ---                        \n",
    "                        trainlogger.log_update(\n",
    "                            train_loss_ema, test_acc, n_train_instances, n_test_instances,\n",
    "                            elapsed_seconds_from_last_check, batch_size, learning_rates[lr_i], 't' if model_updated else 'f')\n",
    "                        \n",
    "                        # --- check for early stopping\n",
    "                        if checks_with_no_improvement >= early_stopping_checks:\n",
    "                            if lr_i + 1 < len(learning_rates):\n",
    "                                lr_i += 1\n",
    "                                checks_with_no_improvement = 0\n",
    "                                print(\"   *** %d checks with no improvements -> using a smaller learning_rate = %f\" % (\n",
    "                                    early_stopping_checks, learning_rates[lr_i]))\n",
    "                            else:\n",
    "                                print(\"   *** %d checks with no improvements -> early stopping :(\" % early_stopping_checks)\n",
    "                                return\n",
    "                        \n",
    "                        # --- reset check variables\n",
    "                        elapsed_seconds_from_last_check = 0\n",
    "            print('====== TIMEOUT ======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  10001489\n",
      "n_batches =  100\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 100100\n",
    "train_minibatches = generate_minibatches(train_instances, train_batch_size)\n",
    "sanity_check_minibatches(train_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tuples =  403310\n",
      "n_batches =  4\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 101000\n",
    "test_minibatches = generate_minibatches(test_instances, test_batch_size)\n",
    "sanity_check_minibatches(test_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001,\n",
       " 0.0006,\n",
       " 0.00035999999999999997,\n",
       " 0.00021599999999999996,\n",
       " 0.00012959999999999998,\n",
       " 7.775999999999999e-05,\n",
       " 4.665599999999999e-05,\n",
       " 2.7993599999999992e-05,\n",
       " 1.6796159999999994e-05,\n",
       " 1.0077695999999996e-05]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = get_decaying_learning_rates(1e-3, 1e-5, 0.6)\n",
    "learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINE_GRAINED_THRESHOLD, VISUAL_CONFIDENCE_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/workspace/pamessina_models/ugallery/VBPR/v8(10M-400K,rsnt50,u(200)i(100l+100v),+p-np,+npfavc-nfavc,fg.6,vcf.1)/'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = ('/mnt/workspace/pamessina_models/ugallery/VBPR/v8(10M-400K,rsnt50,'\n",
    "              'u(200)i(100l+100v),+p-np,+npfavc-nfavc,fg.6,vcf.1)/')\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rates =  [0.001, 0.0006, 0.00035999999999999997, 0.00021599999999999996, 0.00012959999999999998, 7.775999999999999e-05, 4.665599999999999e-05, 2.7993599999999992e-05, 1.6796159999999994e-05, 1.0077695999999996e-05]\n",
      "Variables to be trained:\n",
      "\t <tf.Variable 'user_latent_factors:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel:0' shape=(2048, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>\n",
      "\t <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>\n",
      "\t <tf.Variable 'user_latent_factors/Adam:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'user_latent_factors/Adam_1:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors/Adam:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors/Adam_1:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases/Adam:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases/Adam_1:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias/Adam:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias/Adam_1:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel/Adam:0' shape=(2048, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel/Adam_1:0' shape=(2048, 100) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/pamessina_models/ugallery/VBPR/v9(10M-400K,rsnt50,u(200)i(100l+100v),+p-np,+npfavc-nfavc,fg.6,vcf.1,wd0.000100)/\n",
      "model successfully restored from checkpoint!\n",
      "Before training: test_accuracy = 0.999430\n",
      "Starting training ...\n",
      "train_i=71, train_loss = 0.016296990487, test_accuracy = 0.999400, check_secs = 240.11, total_secs = 240.11\n",
      "train_i=44, train_loss = 0.016336963792, test_accuracy = 0.999340, check_secs = 240.14, total_secs = 480.25\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000600\n",
      "train_i=16, train_loss = 0.016099085910, test_accuracy = 0.999373, check_secs = 240.08, total_secs = 720.33\n",
      "train_i=88, train_loss = 0.016010773109, test_accuracy = 0.999363, check_secs = 240.06, total_secs = 960.39\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000360\n",
      "train_i=60, train_loss = 0.015845824747, test_accuracy = 0.999360, check_secs = 240.09, total_secs = 1200.48\n",
      "train_i=33, train_loss = 0.015791199260, test_accuracy = 0.999375, check_secs = 240.11, total_secs = 1440.59\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000216\n",
      "train_i=6, train_loss = 0.015689015811, test_accuracy = 0.999385, check_secs = 240.18, total_secs = 1680.77\n",
      "train_i=77, train_loss = 0.015655791338, test_accuracy = 0.999358, check_secs = 240.04, total_secs = 1920.80\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000130\n",
      "train_i=49, train_loss = 0.015593693041, test_accuracy = 0.999358, check_secs = 240.17, total_secs = 2160.97\n",
      "train_i=21, train_loss = 0.015574007576, test_accuracy = 0.999355, check_secs = 240.07, total_secs = 2401.04\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000078\n",
      "train_i=92, train_loss = 0.015535273628, test_accuracy = 0.999360, check_secs = 240.17, total_secs = 2641.22\n",
      "train_i=63, train_loss = 0.015524213967, test_accuracy = 0.999370, check_secs = 240.08, total_secs = 2881.30\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000047\n",
      "train_i=34, train_loss = 0.015501640847, test_accuracy = 0.999350, check_secs = 240.01, total_secs = 3121.31\n",
      "train_i=5, train_loss = 0.015493806502, test_accuracy = 0.999355, check_secs = 240.07, total_secs = 3361.38\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000028\n",
      "train_i=78, train_loss = 0.015479530411, test_accuracy = 0.999358, check_secs = 240.12, total_secs = 3601.50\n",
      "train_i=49, train_loss = 0.015475813223, test_accuracy = 0.999350, check_secs = 240.15, total_secs = 3841.65\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000017\n",
      "train_i=19, train_loss = 0.015467972605, test_accuracy = 0.999348, check_secs = 240.04, total_secs = 4081.69\n",
      "train_i=90, train_loss = 0.015464615276, test_accuracy = 0.999358, check_secs = 240.08, total_secs = 4321.77\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000010\n",
      "train_i=61, train_loss = 0.015460187477, test_accuracy = 0.999353, check_secs = 240.12, total_secs = 4561.89\n",
      "train_i=33, train_loss = 0.015458952994, test_accuracy = 0.999350, check_secs = 240.12, total_secs = 4802.01\n",
      "   *** 2 checks with no improvements -> early stopping :(\n",
      "learning_rates =  [0.001, 0.0006, 0.00035999999999999997, 0.00021599999999999996, 0.00012959999999999998, 7.775999999999999e-05, 4.665599999999999e-05, 2.7993599999999992e-05, 1.6796159999999994e-05, 1.0077695999999996e-05]\n",
      "Variables to be trained:\n",
      "\t <tf.Variable 'user_latent_factors:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel:0' shape=(2048, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>\n",
      "\t <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>\n",
      "\t <tf.Variable 'user_latent_factors/Adam:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'user_latent_factors/Adam_1:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors/Adam:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors/Adam_1:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases/Adam:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases/Adam_1:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias/Adam:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias/Adam_1:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel/Adam:0' shape=(2048, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel/Adam_1:0' shape=(2048, 100) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/pamessina_models/ugallery/VBPR/v10(10M-400K,rsnt50,u(200)i(100l+100v),+p-np,+npfavc-nfavc,fg.6,vcf.1,wd0.001000)/\n",
      "model successfully restored from checkpoint!\n",
      "Before training: test_accuracy = 0.996576\n",
      "Starting training ...\n",
      "train_i=71, train_loss = 0.072700450631, test_accuracy = 0.996368, check_secs = 240.08, total_secs = 240.08\n",
      "train_i=44, train_loss = 0.071632326758, test_accuracy = 0.996226, check_secs = 240.08, total_secs = 480.17\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000600\n",
      "train_i=17, train_loss = 0.070708697891, test_accuracy = 0.996254, check_secs = 240.06, total_secs = 720.22\n",
      "train_i=90, train_loss = 0.070261005342, test_accuracy = 0.996130, check_secs = 240.03, total_secs = 960.26\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000360\n",
      "train_i=62, train_loss = 0.069806974918, test_accuracy = 0.996157, check_secs = 240.01, total_secs = 1200.27\n",
      "train_i=34, train_loss = 0.069591615203, test_accuracy = 0.996112, check_secs = 240.01, total_secs = 1440.28\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000216\n",
      "train_i=2, train_loss = 0.069329042764, test_accuracy = 0.996137, check_secs = 240.11, total_secs = 1680.40\n",
      "train_i=37, train_loss = 0.069054418092, test_accuracy = 0.996097, check_secs = 240.11, total_secs = 2160.57\n",
      "train_i=5, train_loss = 0.068988585292, test_accuracy = 0.996110, check_secs = 240.08, total_secs = 2400.65\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000078\n",
      "train_i=78, train_loss = 0.068891756024, test_accuracy = 0.996142, check_secs = 240.07, total_secs = 2640.72\n",
      "train_i=97, train_loss = 0.068854855561, test_accuracy = 0.996112, check_secs = 240.12, total_secs = 2880.84\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_i=78, train_loss = 0.068795979766, test_accuracy = 0.996130, check_secs = 240.15, total_secs = 3120.99\n",
      "train_i=62, train_loss = 0.068774389831, test_accuracy = 0.996112, check_secs = 240.15, total_secs = 3361.14\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000028\n",
      "train_i=48, train_loss = 0.068737726581, test_accuracy = 0.996100, check_secs = 240.02, total_secs = 3601.16\n",
      "train_i=34, train_loss = 0.068725597903, test_accuracy = 0.996122, check_secs = 240.13, total_secs = 3841.29\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000017\n",
      "train_i=18, train_loss = 0.068703808237, test_accuracy = 0.996102, check_secs = 240.07, total_secs = 4081.35\n",
      "train_i=0, train_loss = 0.068696310813, test_accuracy = 0.996107, check_secs = 240.07, total_secs = 4321.42\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000010\n",
      "train_i=82, train_loss = 0.068684157100, test_accuracy = 0.996107, check_secs = 240.06, total_secs = 4561.49\n",
      "train_i=64, train_loss = 0.068680201745, test_accuracy = 0.996115, check_secs = 240.14, total_secs = 4801.63\n",
      "   *** 2 checks with no improvements -> early stopping :(\n",
      "learning_rates =  [0.001, 0.0006, 0.00035999999999999997, 0.00021599999999999996, 0.00012959999999999998, 7.775999999999999e-05, 4.665599999999999e-05, 2.7993599999999992e-05, 1.6796159999999994e-05, 1.0077695999999996e-05]\n",
      "Variables to be trained:\n",
      "\t <tf.Variable 'user_latent_factors:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel:0' shape=(2048, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>\n",
      "\t <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>\n",
      "\t <tf.Variable 'user_latent_factors/Adam:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'user_latent_factors/Adam_1:0' shape=(2919, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors/Adam:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_factors/Adam_1:0' shape=(13297, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases/Adam:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'item_latent_biases/Adam_1:0' shape=(13297,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias/Adam:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'visual_bias/Adam_1:0' shape=(2048,) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel/Adam:0' shape=(2048, 100) dtype=float32_ref>\n",
      "\t <tf.Variable 'trainable_image_embedding/fc1/kernel/Adam_1:0' shape=(2048, 100) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/pamessina_models/ugallery/VBPR/v11(10M-400K,rsnt50,u(200)i(100l+100v),+p-np,+npfavc-nfavc,fg.6,vcf.1,wd0.010000)/\n",
      "model successfully restored from checkpoint!\n",
      "Before training: test_accuracy = 0.961871\n",
      "Starting training ...\n",
      "train_i=81, train_loss = 0.231245380383, test_accuracy = 0.960410, check_secs = 240.04, total_secs = 240.04\n",
      "train_i=64, train_loss = 0.221322922350, test_accuracy = 0.957879, check_secs = 240.08, total_secs = 480.13\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000600\n",
      "train_i=46, train_loss = 0.216079763851, test_accuracy = 0.956654, check_secs = 240.08, total_secs = 720.20\n",
      "train_i=28, train_loss = 0.213575525143, test_accuracy = 0.955578, check_secs = 240.16, total_secs = 960.37\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000360\n",
      "train_i=11, train_loss = 0.212048269210, test_accuracy = 0.955654, check_secs = 240.14, total_secs = 1200.50\n",
      "train_i=93, train_loss = 0.211255099677, test_accuracy = 0.954992, check_secs = 240.06, total_secs = 1440.57\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000216\n",
      "train_i=75, train_loss = 0.210586176722, test_accuracy = 0.955020, check_secs = 240.04, total_secs = 1680.61\n",
      "train_i=57, train_loss = 0.210216237871, test_accuracy = 0.955000, check_secs = 240.08, total_secs = 1920.69\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000130\n",
      "train_i=38, train_loss = 0.209852531453, test_accuracy = 0.955089, check_secs = 240.00, total_secs = 2160.69\n",
      "train_i=19, train_loss = 0.209657699059, test_accuracy = 0.955030, check_secs = 240.08, total_secs = 2400.77\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000078\n",
      "train_i=1, train_loss = 0.209451369493, test_accuracy = 0.954772, check_secs = 240.06, total_secs = 2640.83\n",
      "train_i=88, train_loss = 0.209346083097, test_accuracy = 0.954960, check_secs = 240.13, total_secs = 2880.96\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000047\n",
      "train_i=76, train_loss = 0.209221513672, test_accuracy = 0.954769, check_secs = 240.02, total_secs = 3120.98\n",
      "train_i=64, train_loss = 0.209160027798, test_accuracy = 0.954722, check_secs = 240.01, total_secs = 3360.99\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000028\n",
      "train_i=52, train_loss = 0.209083784259, test_accuracy = 0.954819, check_secs = 240.03, total_secs = 3601.02\n",
      "train_i=41, train_loss = 0.209047301670, test_accuracy = 0.954878, check_secs = 240.07, total_secs = 3841.09\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000017\n",
      "train_i=28, train_loss = 0.208999109244, test_accuracy = 0.954742, check_secs = 240.00, total_secs = 4081.09\n",
      "train_i=17, train_loss = 0.208976314928, test_accuracy = 0.954732, check_secs = 240.17, total_secs = 4321.27\n",
      "   *** 2 checks with no improvements -> using a smaller learning_rate = 0.000010\n",
      "train_i=5, train_loss = 0.208948805652, test_accuracy = 0.954762, check_secs = 240.11, total_secs = 4561.38\n",
      "train_i=94, train_loss = 0.208940797470, test_accuracy = 0.954787, check_secs = 240.11, total_secs = 4801.49\n",
      "   *** 2 checks with no improvements -> early stopping :(\n"
     ]
    }
   ],
   "source": [
    "for _v, _wd in zip((9,10,11), (0.0001, 0.001, 0.01)):\n",
    "    \n",
    "    MODEL_PATH = ('/mnt/workspace/pamessina_models/ugallery/VBPR/v%d(10M-400K,rsnt50,'\n",
    "              'u(200)i(100l+100v),+p-np,+npfavc-nfavc,fg.6,vcf.1,wd%f)/') % (_v, _wd)\n",
    "    \n",
    "    train_network(\n",
    "        train_minibatches, test_minibatches,\n",
    "        len(train_instances), len(test_instances),\n",
    "        batch_size=train_batch_size,    \n",
    "        pretrained_embeddings=concat_featmat,\n",
    "        user_latent_dim=200,\n",
    "        item_latent_dim=100,\n",
    "        item_visual_dim=100,\n",
    "        model_path = MODEL_PATH,\n",
    "        max_seconds_training=3600*2,\n",
    "        min_seconds_to_check_improvement=60*4,\n",
    "        early_stopping_checks=2,\n",
    "        weight_decay=_wd,\n",
    "        learning_rates=learning_rates,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
