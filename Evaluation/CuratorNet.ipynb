{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack based on https://stackoverflow.com/a/33532002\n",
    "from inspect import getsourcefile\n",
    "import os.path as path, sys\n",
    "current_dir = path.dirname(path.abspath(getsourcefile(lambda:0)))\n",
    "sys.path.insert(0, current_dir[:current_dir.rfind(path.sep)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport FeatureUtils\n",
    "%aimport ExperimentUtils\n",
    "%aimport Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import FeatureUtils as featils\n",
    "from Classes import Customer, ProfileBase\n",
    "from ExperimentUtils import sanity_check_purchase_upload_events, recommendations_to_csv,\\\n",
    "        run_personalized_recommendation_experiment\n",
    "from TransactionsUtils import TransactionsHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featils.read_numpy_features_matrix(\n",
    "    ('/mnt/workspace/Ugallery/Youtube-like/v21(10M-400K,avg+max,rsnt50,u(300,300,200)i(200,200),+p(rl&fk)-np,+npfavc(rl&fk)-nfavc,+nxt+hdaccklst-nfavc,fg.6,vcf.1,wd.01)/'),\n",
    "    'item_vectors.npy', 'ids')\n",
    "item_embeddings = tmp['features']\n",
    "id2index = tmp['id2index']\n",
    "index2id = tmp['index2id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 200)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13297"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_with_features = set(index2id)\n",
    "len(ids_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks_dict = TransactionsHandler.artworks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_dict = { cid : Customer() for cid in TransactionsHandler.valid_sales_df.customer_id.unique() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- upload events -----\n",
    "upload_events = TransactionsHandler.upload_events\n",
    "\n",
    "# ---- purchase events -----\n",
    "purchase_session_events = TransactionsHandler.purchase_session_events\n",
    "\n",
    "# distribute purchases among customers\n",
    "for pe in purchase_session_events:\n",
    "    customers_dict[pe.customer_id].append_purchase_session(pe)\n",
    "\n",
    "# --- join events and sort by timestamp ----\n",
    "time_events = upload_events + purchase_session_events\n",
    "time_events.sort(key=lambda x : x.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(upload_events) =  7742\n",
      "len(purchase_session_events) =  4897\n",
      "len(time_events) =  12639\n"
     ]
    }
   ],
   "source": [
    "print(\"len(upload_events) = \", len(upload_events))\n",
    "print(\"len(purchase_session_events) = \", len(purchase_session_events))\n",
    "print(\"len(time_events) = \", len(time_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK: event types are correct\n",
      "CHECK: events ordered by timestamp\n",
      "CHECK: products are only uploaded once\n",
      "CHECK: products can only be purchased if present in inventory\n"
     ]
    }
   ],
   "source": [
    "sanity_check_purchase_upload_events(time_events, artworks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "REC_SIZE = 20\n",
    "MAX_PROFILE_SIZES = [None]\n",
    "MAX_PROFILE_TAGS = ['_(maxprofsize=oo)' if size is None else ('_(maxprofsize=%d)' % size)\n",
    "                                                                for size in MAX_PROFILE_SIZES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([None], ['_(maxprofsize=oo)'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_PROFILE_SIZES, MAX_PROFILE_TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuratorNetProfile(ProfileBase):\n",
    "    # --- global -----        \n",
    "    @classmethod\n",
    "    def global_purchase_session_event_handler(cls, purch_sess):\n",
    "        pass\n",
    "\n",
    "    # --- instance ----    \n",
    "    def __init__(self, maxprofsize, artworks_dict, network, sess):\n",
    "        ProfileBase.__init__(self, maxprofsize, artworks_dict)\n",
    "        self._network = network\n",
    "        self._sess = sess\n",
    "    def ready(self):\n",
    "        return len(self.consumed_artworks) > 0    \n",
    "    def handle_artwork_added(self, artwork):\n",
    "        pass        \n",
    "    def handle_artwork_removed(self, artwork):\n",
    "        pass\n",
    "    def rank_inventory_ids(self, inventory_artworks):\n",
    "        profile_indexes = [id2index[a.id] for a in self.consumed_artworks]\n",
    "        inventory_indexes = [id2index[a.id] for a in inventory_artworks]\n",
    "        match_scores = self._network.get_match_scores(self._sess,\n",
    "            item_embeddings, profile_indexes, inventory_indexes)\n",
    "        pairs = [(s,i) for s,i in zip(match_scores, inventory_indexes)]\n",
    "        pairs.sort(reverse=True)\n",
    "        return [index2id[p[1]] for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Networks import CuratorNet_Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(artworks_dict, customers_dict, time_events, version, version_kwargs, version_alias=None):\n",
    "    if version_alias is None:\n",
    "        version_alias = version\n",
    "    with tf.Graph().as_default():\n",
    "        network = CuratorNet_Evaluation(**version_kwargs)\n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(\n",
    "                '/mnt/workspace/pamessina_models/ugallery/youtube_like/%s/' % version))\n",
    "            for maxprofsize, maxproftag in zip(MAX_PROFILE_SIZES, MAX_PROFILE_TAGS):\n",
    "                create_profile_func = lambda _: CuratorNetProfile(maxprofsize, artworks_dict, network, sess)\n",
    "                recommendations = run_personalized_recommendation_experiment(\n",
    "                    artworks_dict, customers_dict, time_events, create_profile_func, rec_size=REC_SIZE)\n",
    "                recommendations_to_csv(\n",
    "                    recommendations,\n",
    "                    (\"/mnt/workspace/ugallery_experiment_results/@{}{}_curatornet-{}.csv\").format(\n",
    "                        REC_SIZE, maxproftag, version_alias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v21(10M-400K,avg+max,rsnt50,u(300,300,200)i(200,200),+p(rl&fk)-np,+npfavc(rl&fk)-nfavc,+nxt+hdaccklst-nfavc,fg.6,vcf.1,wd.01)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = 'v21(10M-400K,avg+max,rsnt50,u(300,300,200)i(200,200),+p(rl&fk)-np,+npfavc(rl&fk)-nfavc,+nxt+hdaccklst-nfavc,fg.6,vcf.1,wd.01)'\n",
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/pamessina_models/ugallery/youtube_like/v21(10M-400K,avg+max,rsnt50,u(300,300,200)i(200,200),+p(rl&fk)-np,+npfavc(rl&fk)-nfavc,+nxt+hdaccklst-nfavc,fg.6,vcf.1,wd.01)/\n",
      "---------- starting experiment ------------\n",
      "500 tests done! elapsed time: 3.98 seconds\n",
      "1000 tests done! elapsed time: 7.95 seconds\n",
      "1500 tests done! elapsed time: 12.28 seconds\n",
      "1978 tests done! elapsed time: 16.45 seconds\n",
      "** recommendations successfully saved to /mnt/workspace/ugallery_experiment_results/@20_(maxprofsize=oo)_curatornet-v21(10M-400K,avg+max,rsnt50,u(300,300,200)i(200,200),+p(rl&fk)-np,+npfavc(rl&fk)-nfavc,+nxt+hdaccklst-nfavc,fg.6,vcf.1,wd.01).csv\n"
     ]
    }
   ],
   "source": [
    "run_experiments(artworks_dict, customers_dict, time_events,\n",
    "                version=version,\n",
    "                version_kwargs=dict(\n",
    "                    user_layer_units=[300,300,200],\n",
    "                    latent_space_dim=200,\n",
    "                    profile_pooling_mode='AVG+MAX',\n",
    "                ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
